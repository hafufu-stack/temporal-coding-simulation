# 【SNN】ついに「33桁（100億の100億倍以上）」の計算に成功！！時間領域コンピューティングの夜明け

## はじめに
[前回の記事](https://zenn.dev/cell_activation/articles/48876f4acb28f0)では、わずか10個のニューロンに100ビット以上の情報を「記憶」させることに成功しました。

「記憶できるなら、計算もできるんじゃないか？」

そう思って早速試してみたところ、**30ニューロンを使って111ビット（10進数で約33桁）同士の足し算**にあっさり成功してしまいました。これは、人類が従来の0/1のデジタル計算から、脳と同じ「時間制御による計算」へシフトする第一歩かもしれません。

今回は、その**「時間領域演算（Time-Domain Computing）」**の仕組みと実装コードを公開します。

## 今回作ったもの：30ニューロン加算器
作ったのは、2つの巨大な数値を足し算するSNN（スパイキングニューラルネットワーク）です。

### スペック
- **ニューロン数**: 合計30個
    - 入力層A: 10個（足される数）
    - 入力層B: 10個（足す数）
    - 演算層C: 10個（結果出力）
- **扱える情報量**: 111ビット（約3.0 x 10^33）
- **計算方式**: 時間相関符号化を用いたアナログ時間加算

30個のニューロンだけで、スーパーコンピュータで扱うような巨大な整数の加算ができてしまう。これがSNNの恐ろしさです。

## 仕組み：なぜ「時間」で計算できるのか？

### 1. 情報を「タイミング」に込める
前回同様、**「いつ発火するか（位相）」**と**「間隔はどれくらいか（ISI）」**に情報を詰め込んでいます。
1つのニューロンペアが、数ビット分の情報を担当します。

### 2. 足し算 ＝ 波の重ね合わせ
普通のコンピュータは、電子回路のゲートを開け閉めして計算しますが、このシステムは物理現象に近いです。
ニューロンの膜電位は、入力電流が入ると上がります。

- 数値Aの信号が来るタイミング: $t_A$
- 数値Bの信号が来るタイミング: $t_B$
- ニューロンが受け取る合計: $t_A + t_B$ のような単純な和ではなく、適切なタイミングで信号を送ることで、**膜電位のピークが「足し算の結果に対応する時刻」にズレる**ように設計しています。

### 3. SNNコードの核（add関数）
Pythonコードの一部です。「時間パラメータ」を足し合わせているのが分かります。

```python
def add(self, A, B):
    # (中略)
    # パターンを加算（キャリー伝播付き）
    patterns_C = self.encoder.add_patterns(patterns_A, patterns_B)
    
    # 各群の入力タイミングを計算
    # これにより、物理シミュレーション上で「計算」が実行される
```

桁上がり（Carry）の処理も実装済みです。下の位のニューロンペアから溢れた情報は、上の位のニューロンペアにしっかり受け継がれます。

## 実験結果

### 1-12桁のランダムな加算テスト
Pythonスクリプトを実行すると、ランダムな桁数の足し算をテストします。

```text
[1/4] 82,345,678,901 + 12,345,678,901 = ?
  [OK] 結果: 94,691,357,802 (正解)
```
Pythonの標準演算（正解）と完全に一致しています。

### データの可視化
これが実際のニューロンの動きです。
（※ここに実行時に表示される3段のグラフ画像を貼るとGoodです）

- **上段**: 入力Aの波形（10ニューロン分）
- **中段**: 入力Bの波形（10ニューロン分）
- **下段**: 演算結果Cの波形

上と中段の波が合体して、下段の波（答え）になっている様子が見て取れます。特に10色の線が複雑に絡み合いながらも、正確に答えのタイミングで発火しているのは芸術的です。

## ソースコード公開
GitHubにコードを上げました。`snn-operation/30-neuron-adder.py` です。
ランダムモード（`RANDOM_MODE = 1`）で動かすと、毎回違う巨大数の計算が見れて面白いですよ。

https://github.com/kyjan/neural-coding-simulation/blob/main/snn-operation/30-neuron-adder.py 
*(※URLは仮です)*

## まとめ：そして「SNN暗号・圧縮」へ...
たった30個のニューロンで、我々が普段使っている電卓よりも遥かに巨大な数を扱えることが証明できました。
しかもこれは、単なる計算以外にも応用可能です。

実は今、このシステムを応用して：
1. **SNNカオス暗号**: バタフライ効果を利用した解読不能な暗号
2. **SNN予測圧縮**: 脳の予測機能を使った次世代データ圧縮

の開発も進めています。これらもRyzen AIのようなNPUと組み合わせれば、とんでもないパフォーマンスが出る予感がしています。

次回の記事もお楽しみに！
