"""
SNN AI Interpretability: Advanced Deep Dive
============================================

ã‚ˆã‚Šè©³ç´°ãªè§£æ:
1. ResNet-18ã§ã®æ¤œè¨¼ï¼ˆå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ï¼‰
2. ã‚¯ãƒ©ã‚¹åˆ¥TTFS/Synchronyãƒ‘ã‚¿ãƒ¼ãƒ³æ¯”è¼ƒ
3. Softmaxç¢ºç‡ vs ã‚¸ãƒƒã‚¿ãƒ¼ç›¸é–¢åˆ†æ
4. å¼·åŒ–ãƒã‚¤ã‚ºã§ã®ã‚¹ãƒ‘ã‚¤ã‚¯å®‰å®šæ€§

Author: ã‚ãƒ¼ã‚‹ (Cell Activation)
Date: 2026-02-04
"""

import os
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['font.family'] = ['MS Gothic', 'DejaVu Sans']

print("=" * 70)
print("ğŸ§  SNN AI Interpretability: Advanced Deep Dive")
print("=" * 70)


# =============================================================================
# 1. ResNet-like Modelï¼ˆã‚ˆã‚Šå¤§è¦æ¨¡ï¼‰
# =============================================================================
class ResBlock(nn.Module):
    """Residual Block"""
    def __init__(self, in_ch, out_ch, stride=1):
        super().__init__()
        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_ch)
        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_ch)
        
        self.shortcut = nn.Sequential()
        if stride != 1 or in_ch != out_ch:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_ch, out_ch, 1, stride=stride, bias=False),
                nn.BatchNorm2d(out_ch)
            )
    
    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = F.relu(out)
        return out


class SmallResNet(nn.Module):
    """Small ResNet for CIFAR-10"""
    def __init__(self, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 64, 3, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        
        self.layer1 = self._make_layer(64, 64, 2)
        self.layer2 = self._make_layer(64, 128, 2, stride=2)
        self.layer3 = self._make_layer(128, 256, 2, stride=2)
        
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(256, num_classes)
        
        # æ´»æ€§åŒ–ä¿å­˜ç”¨
        self.activations = {}
    
    def _make_layer(self, in_ch, out_ch, blocks, stride=1):
        layers = [ResBlock(in_ch, out_ch, stride)]
        for _ in range(1, blocks):
            layers.append(ResBlock(out_ch, out_ch))
        return nn.Sequential(*layers)
    
    def forward(self, x, save_activations=False):
        x = F.relu(self.bn1(self.conv1(x)))
        if save_activations:
            self.activations['conv1'] = x.clone()
        
        x = self.layer1(x)
        if save_activations:
            self.activations['layer1'] = x.clone()
        
        x = self.layer2(x)
        if save_activations:
            self.activations['layer2'] = x.clone()
        
        x = self.layer3(x)
        if save_activations:
            self.activations['layer3'] = x.clone()
        
        x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        if save_activations:
            self.activations['avgpool'] = x.clone()
        
        x = self.fc(x)
        return x
    
    def get_activations(self, x):
        self.activations = {}
        output = self.forward(x, save_activations=True)
        self.activations['output'] = output
        return self.activations


# =============================================================================
# 2. Advanced SNN Analyzer
# =============================================================================
class AdvancedSNNAnalyzer:
    """é«˜åº¦ãªSNNè§£æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, alpha=2.0, timesteps=100):
        self.alpha = alpha
        self.timesteps = timesteps
    
    def compute_ttfs(self, activation):
        """TTFSè¨ˆç®—ï¼ˆé«˜ç²¾åº¦ç‰ˆï¼‰"""
        ttfs = torch.full_like(activation, float(self.timesteps))
        active_mask = activation > 0
        
        if active_mask.any():
            max_act = activation.max()
            if max_act > 0:
                normalized = activation[active_mask] / max_act
                ttfs[active_mask] = self.timesteps * (1 - normalized)
        
        return ttfs
    
    def analyze_ttfs_by_class(self, model, dataloader, class_names, num_samples_per_class=10):
        """ã‚¯ãƒ©ã‚¹åˆ¥TTFSåˆ†æ"""
        class_ttfs = defaultdict(list)
        class_counts = defaultdict(int)
        
        model.eval()
        with torch.no_grad():
            for data, target in dataloader:
                class_idx = target.item()
                if class_counts[class_idx] >= num_samples_per_class:
                    continue
                
                activations = model.get_activations(data)
                
                for layer_name, act in activations.items():
                    if layer_name == 'output':
                        continue
                    ttfs = self.compute_ttfs(act)
                    
                    if len(class_ttfs[class_idx]) == 0:
                        class_ttfs[class_idx] = {layer_name: [] for layer_name in activations.keys() if layer_name != 'output'}
                    
                    class_ttfs[class_idx][layer_name].append(ttfs.mean().item())
                
                class_counts[class_idx] += 1
                
                if all(c >= num_samples_per_class for c in class_counts.values()):
                    break
        
        # å¹³å‡è¨ˆç®—
        class_ttfs_avg = {}
        for class_idx, layer_dict in class_ttfs.items():
            class_ttfs_avg[class_names[class_idx]] = {
                layer: np.mean(values) for layer, values in layer_dict.items()
            }
        
        return class_ttfs_avg
    
    def compute_synchrony_ratio(self, ttfs_tensor, tolerance=5.0):
        """åŒæœŸæ¯”ç‡ã‚’é«˜é€Ÿè¨ˆç®—"""
        if len(ttfs_tensor.shape) > 2:
            ttfs_flat = ttfs_tensor.view(ttfs_tensor.size(0), -1)
        else:
            ttfs_flat = ttfs_tensor
        
        n = ttfs_flat.size(1)
        if n > 200:  # å¤§ãã™ãã‚‹å ´åˆã¯ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            indices = torch.randperm(n)[:200]
            ttfs_flat = ttfs_flat[:, indices]
            n = 200
        
        sync_count = 0
        total_pairs = 0
        
        for i in range(n):
            for j in range(i+1, n):
                diff = torch.abs(ttfs_flat[0, i] - ttfs_flat[0, j])
                if diff < tolerance:
                    sync_count += 1
                total_pairs += 1
        
        return sync_count / total_pairs if total_pairs > 0 else 0
    
    def spike_stability_with_confidence(self, model, x, num_trials=20, noise_levels=[0.01, 0.05, 0.1, 0.2]):
        """Softmaxç¢ºç‡ã¨ã‚¸ãƒƒã‚¿ãƒ¼ã®ç›¸é–¢åˆ†æ"""
        results = {}
        
        model.eval()
        with torch.no_grad():
            # å…ƒã®äºˆæ¸¬
            output = model(x)
            probs = F.softmax(output, dim=1)
            pred = output.argmax(dim=1)
            confidence = probs.max().item()
            
            results['prediction'] = pred.item()
            results['confidence'] = confidence
            results['noise_analysis'] = {}
            
            for noise_std in noise_levels:
                jitters = []
                pred_changes = 0
                
                for trial in range(num_trials):
                    noisy_x = x + torch.randn_like(x) * noise_std
                    noisy_x = torch.clamp(noisy_x, 0, 1)
                    
                    noisy_output = model(noisy_x)
                    noisy_pred = noisy_output.argmax(dim=1)
                    
                    if noisy_pred.item() != pred.item():
                        pred_changes += 1
                    
                    # æ´»æ€§åŒ–å–å¾—ã—ã¦TTFSè¨ˆç®—
                    noisy_act = model.get_activations(noisy_x)
                    layer_jitters = []
                    for layer_name, act in noisy_act.items():
                        if layer_name == 'output':
                            continue
                        ttfs = self.compute_ttfs(act)
                        layer_jitters.append(ttfs.std().item())
                    
                    jitters.append(np.mean(layer_jitters))
                
                results['noise_analysis'][noise_std] = {
                    'mean_jitter': np.mean(jitters),
                    'jitter_std': np.std(jitters),
                    'prediction_stability': 1 - (pred_changes / num_trials)
                }
        
        return results


# =============================================================================
# 3. ãƒ‡ãƒ¼ã‚¿æº–å‚™
# =============================================================================
print("\nã€1. CIFAR-10ãƒ‡ãƒ¼ã‚¿æº–å‚™ã€‘")
from torchvision import datasets, transforms

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

train_subset = torch.utils.data.Subset(train_dataset, range(8000))
test_subset = torch.utils.data.Subset(test_dataset, range(500))

train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_subset, batch_size=1, shuffle=False)

class_names = ['airplane', 'car', 'bird', 'cat', 'deer', 
               'dog', 'frog', 'horse', 'ship', 'truck']

print(f"  è¨“ç·´: {len(train_subset)}, ãƒ†ã‚¹ãƒˆ: {len(test_subset)}")


# =============================================================================
# 4. ResNetãƒ¢ãƒ‡ãƒ«å­¦ç¿’
# =============================================================================
print("\nã€2. SmallResNetå­¦ç¿’ã€‘")
model = SmallResNet(num_classes=10)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

epochs = 15
for epoch in range(epochs):
    model.train()
    for data, target in train_loader:
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
    
    if (epoch + 1) % 5 == 0:
        model.eval()
        correct = 0
        with torch.no_grad():
            for data, target in test_loader:
                output = model(data)
                pred = output.argmax(dim=1)
                correct += (pred == target).sum().item()
        acc = 100.0 * correct / len(test_subset)
        print(f"  Epoch {epoch+1}: Accuracy = {acc:.1f}%")

print(f"\n  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†ï¼")


# =============================================================================
# 5. ã‚¯ãƒ©ã‚¹åˆ¥TTFSåˆ†æ
# =============================================================================
print("\nã€3. ã‚¯ãƒ©ã‚¹åˆ¥TTFSåˆ†æã€‘")

analyzer = AdvancedSNNAnalyzer(alpha=2.0, timesteps=100)
class_ttfs = analyzer.analyze_ttfs_by_class(model, test_loader, class_names, num_samples_per_class=20)

print(f"\n  ã‚¯ãƒ©ã‚¹åˆ¥Layer1å¹³å‡TTFS:")
print(f"  {'-'*40}")
layer1_ttfs = [(cls, vals.get('layer1', 0)) for cls, vals in class_ttfs.items()]
layer1_ttfs.sort(key=lambda x: x[1])
for cls, ttfs in layer1_ttfs:
    bar = 'â–ˆ' * int(ttfs / 5)
    print(f"  {cls:<10} | {ttfs:>6.2f} | {bar}")


# =============================================================================
# 6. ã‚¯ãƒ©ã‚¹åˆ¥Synchronyåˆ†æ
# =============================================================================
print("\nã€4. ã‚¯ãƒ©ã‚¹åˆ¥Synchronyåˆ†æã€‘")

class_sync = defaultdict(list)
class_counts = defaultdict(int)

model.eval()
with torch.no_grad():
    for data, target in test_loader:
        class_idx = target.item()
        if class_counts[class_idx] >= 10:
            continue
        
        activations = model.get_activations(data)
        
        # Layer3ã§ã®åŒæœŸç‡
        ttfs = analyzer.compute_ttfs(activations['layer3'])
        sync_ratio = analyzer.compute_synchrony_ratio(ttfs, tolerance=10.0)
        class_sync[class_names[class_idx]].append(sync_ratio)
        
        class_counts[class_idx] += 1
        if all(c >= 10 for c in class_counts.values()):
            break

print(f"\n  ã‚¯ãƒ©ã‚¹åˆ¥Layer3åŒæœŸç‡:")
print(f"  {'-'*50}")
sync_avgs = [(cls, np.mean(vals)) for cls, vals in class_sync.items()]
sync_avgs.sort(key=lambda x: -x[1])
for cls, sync in sync_avgs:
    bar = 'â–ˆ' * int(sync * 50)
    print(f"  {cls:<10} | {sync*100:>6.2f}% | {bar}")


# =============================================================================
# 7. Softmaxç¢ºç‡ vs ã‚¸ãƒƒã‚¿ãƒ¼ç›¸é–¢åˆ†æ
# =============================================================================
print("\nã€5. Softmaxç¢ºç‡ vs ã‚¸ãƒƒã‚¿ãƒ¼ç›¸é–¢åˆ†æã€‘")

confidences = []
jitters = []
correct_flags = []

model.eval()
sample_count = 0
with torch.no_grad():
    for data, target in test_loader:
        if sample_count >= 100:  # 100ã‚µãƒ³ãƒ—ãƒ«åˆ†æ
            break
        
        result = analyzer.spike_stability_with_confidence(model, data, num_trials=10, noise_levels=[0.1])
        
        confidences.append(result['confidence'])
        jitters.append(result['noise_analysis'][0.1]['mean_jitter'])
        correct_flags.append(1 if result['prediction'] == target.item() else 0)
        
        sample_count += 1
        if sample_count % 25 == 0:
            print(f"  å‡¦ç†ä¸­... {sample_count}/100")

# ç›¸é–¢è¨ˆç®—
correlation, p_value = stats.pearsonr(confidences, jitters)
print(f"\n  çµæœ:")
print(f"  {'-'*50}")
print(f"  Softmaxç¢ºç‡ vs ã‚¸ãƒƒã‚¿ãƒ¼ç›¸é–¢ä¿‚æ•°: {correlation:.4f} (p={p_value:.4f})")

# æ­£è§£/ä¸æ­£è§£åˆ¥
correct_conf = [c for c, f in zip(confidences, correct_flags) if f == 1]
correct_jit = [j for j, f in zip(jitters, correct_flags) if f == 1]
incorrect_conf = [c for c, f in zip(confidences, correct_flags) if f == 0]
incorrect_jit = [j for j, f in zip(jitters, correct_flags) if f == 0]

print(f"\n  æ­£è§£ã‚µãƒ³ãƒ—ãƒ« (n={len(correct_conf)}):")
print(f"    å¹³å‡ç¢ºä¿¡åº¦: {np.mean(correct_conf):.4f}")
print(f"    å¹³å‡ã‚¸ãƒƒã‚¿ãƒ¼: {np.mean(correct_jit):.4f}")

if incorrect_conf:
    print(f"\n  ä¸æ­£è§£ã‚µãƒ³ãƒ—ãƒ« (n={len(incorrect_conf)}):")
    print(f"    å¹³å‡ç¢ºä¿¡åº¦: {np.mean(incorrect_conf):.4f}")
    print(f"    å¹³å‡ã‚¸ãƒƒã‚¿ãƒ¼: {np.mean(incorrect_jit):.4f}")


# =============================================================================
# 8. äºˆæ¸¬å®‰å®šæ€§åˆ†æï¼ˆãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«åˆ¥ï¼‰
# =============================================================================
print("\nã€6. äºˆæ¸¬å®‰å®šæ€§åˆ†æï¼ˆãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«åˆ¥ï¼‰ã€‘")

noise_stability = defaultdict(list)

model.eval()
with torch.no_grad():
    sample_count = 0
    for data, target in test_loader:
        if sample_count >= 30:
            break
        
        result = analyzer.spike_stability_with_confidence(
            model, data, num_trials=10, noise_levels=[0.01, 0.05, 0.1, 0.2, 0.3]
        )
        
        for noise, analysis in result['noise_analysis'].items():
            noise_stability[noise].append(analysis['prediction_stability'])
        
        sample_count += 1

print(f"\n  ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«åˆ¥äºˆæ¸¬å®‰å®šæ€§:")
print(f"  {'-'*40}")
for noise in sorted(noise_stability.keys()):
    stability = np.mean(noise_stability[noise]) * 100
    bar = 'â–ˆ' * int(stability / 5)
    print(f"  noise={noise:<5} | {stability:>6.1f}% | {bar}")


# =============================================================================
# 9. å¯è¦–åŒ–
# =============================================================================
print("\nã€7. å¯è¦–åŒ–ã€‘")

fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# ã‚¯ãƒ©ã‚¹åˆ¥TTFS
ax = axes[0, 0]
classes = [x[0] for x in layer1_ttfs]
ttfs_vals = [x[1] for x in layer1_ttfs]
colors = plt.cm.viridis(np.linspace(0, 1, len(classes)))
bars = ax.barh(classes, ttfs_vals, color=colors)
ax.set_xlabel('Mean TTFS (Layer1)')
ax.set_title('TTFS by Class (Lower = Earlier Processing)')

# ã‚¯ãƒ©ã‚¹åˆ¥Synchrony
ax = axes[0, 1]
classes = [x[0] for x in sync_avgs]
sync_vals = [x[1] * 100 for x in sync_avgs]
colors = plt.cm.plasma(np.linspace(0, 1, len(classes)))
bars = ax.barh(classes, sync_vals, color=colors)
ax.set_xlabel('Synchrony Ratio (%)')
ax.set_title('Neural Synchrony by Class (Layer3)')

# Softmax vs Jitteræ•£å¸ƒå›³
ax = axes[0, 2]
colors = ['green' if f else 'red' for f in correct_flags]
ax.scatter(confidences, jitters, c=colors, alpha=0.7)
ax.set_xlabel('Softmax Confidence')
ax.set_ylabel('Mean Jitter')
ax.set_title(f'Confidence vs Jitter (r={correlation:.3f})')
ax.legend(handles=[plt.Line2D([0], [0], marker='o', color='green', label='Correct', linestyle=''),
                   plt.Line2D([0], [0], marker='o', color='red', label='Incorrect', linestyle='')])

# æ­£è§£/ä¸æ­£è§£ã®ã‚¸ãƒƒã‚¿ãƒ¼ç®±ã²ã’å›³
ax = axes[1, 0]
data_to_plot = [correct_jit]
labels = ['Correct']
if incorrect_jit:
    data_to_plot.append(incorrect_jit)
    labels.append('Incorrect')
bp = ax.boxplot(data_to_plot, labels=labels, patch_artist=True)
bp['boxes'][0].set_facecolor('lightgreen')
if len(bp['boxes']) > 1:
    bp['boxes'][1].set_facecolor('lightcoral')
ax.set_ylabel('Mean Jitter')
ax.set_title('Jitter Distribution: Correct vs Incorrect')

# ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«åˆ¥å®‰å®šæ€§
ax = axes[1, 1]
noise_levels = sorted(noise_stability.keys())
stabilities = [np.mean(noise_stability[n]) * 100 for n in noise_levels]
ax.plot(noise_levels, stabilities, 'bo-', linewidth=2, markersize=8)
ax.fill_between(noise_levels, stabilities, alpha=0.3)
ax.set_xlabel('Noise Level (std)')
ax.set_ylabel('Prediction Stability (%)')
ax.set_title('Prediction Stability vs Noise Level')
ax.set_ylim(0, 105)
ax.grid(True, alpha=0.3)

# ç¢ºä¿¡åº¦åˆ†å¸ƒ
ax = axes[1, 2]
ax.hist(correct_conf, bins=15, alpha=0.7, label='Correct', color='green')
if incorrect_conf:
    ax.hist(incorrect_conf, bins=15, alpha=0.7, label='Incorrect', color='red')
ax.set_xlabel('Softmax Confidence')
ax.set_ylabel('Count')
ax.set_title('Confidence Distribution')
ax.legend()

plt.tight_layout()
plt.savefig('snn_interpretability_advanced.png', dpi=150, bbox_inches='tight')
print("  ä¿å­˜: snn_interpretability_advanced.png")


# =============================================================================
# 10. ç™ºè¦‹ã¾ã¨ã‚
# =============================================================================
print("\n" + "=" * 70)
print("ğŸ”¬ Advanced SNN Interpretability ç™ºè¦‹ã¾ã¨ã‚")
print("=" * 70)

print(f"""
ã€ã‚¯ãƒ©ã‚¹åˆ¥TTFSåˆ†æã€‘
  - ã‚¯ãƒ©ã‚¹ã«ã‚ˆã£ã¦å‡¦ç†å„ªå…ˆåº¦ãŒç•°ãªã‚‹
  - ã€Œ{layer1_ttfs[0][0]}ã€ãŒæœ€ã‚‚æ—©ãå‡¦ç†ã•ã‚Œã‚‹ï¼ˆTTFS={layer1_ttfs[0][1]:.2f}ï¼‰
  - ã€Œ{layer1_ttfs[-1][0]}ã€ãŒæœ€ã‚‚é…ãå‡¦ç†ã•ã‚Œã‚‹ï¼ˆTTFS={layer1_ttfs[-1][1]:.2f}ï¼‰
  â†’ AIã¯ç‰¹å®šã®ã‚¯ãƒ©ã‚¹ã‚’ã€Œè¦‹ã¤ã‘ã‚„ã™ã„ã€å‚¾å‘ãŒã‚ã‚‹

ã€ã‚¯ãƒ©ã‚¹åˆ¥Neural Synchronyã€‘
  - ã€Œ{sync_avgs[0][0]}ã€ãŒæœ€ã‚‚é«˜ã„åŒæœŸç‡ï¼ˆ{sync_avgs[0][1]*100:.1f}%ï¼‰
  - åŒæœŸç‡ãŒé«˜ã„ã‚¯ãƒ©ã‚¹ = ç‰¹å¾´ãŒæ˜ç¢ºã§çµ±åˆã•ã‚Œã‚„ã™ã„
  â†’ ã€Œæ¦‚å¿µã®çµåˆåº¦ã€ãŒã‚¯ãƒ©ã‚¹è­˜åˆ¥ã®é›£æ˜“åº¦ã‚’åæ˜ 

ã€Softmaxç¢ºç‡ vs ã‚¸ãƒƒã‚¿ãƒ¼ç›¸é–¢ã€‘
  - ç›¸é–¢ä¿‚æ•°: {correlation:.4f}
  - {'è² ã®ç›¸é–¢ = ç¢ºä¿¡åº¦ãŒé«˜ã„ã»ã©ã‚¸ãƒƒã‚¿ãƒ¼ãŒå°ã•ã„ï¼ˆå®‰å®šï¼‰' if correlation < 0 else 'æ­£ã®ç›¸é–¢ = ç¢ºä¿¡åº¦ãŒé«˜ã„ã»ã©ã‚¸ãƒƒã‚¿ãƒ¼ãŒå¤§ãã„ï¼ˆèˆˆå‘³æ·±ã„ï¼‰'}
  â†’ ã‚¸ãƒƒã‚¿ãƒ¼ã¯ã€Œæœ¬å½“ã®ç¢ºä¿¡åº¦ã€ã®æ–°ã—ã„æŒ‡æ¨™ã«ãªã‚Šã†ã‚‹

ã€äºˆæ¸¬å®‰å®šæ€§ï¼ˆãƒã‚¤ã‚ºè€æ€§ï¼‰ã€‘
  - ãƒã‚¤ã‚º0.01: {np.mean(noise_stability[0.01])*100:.1f}%å®‰å®š
  - ãƒã‚¤ã‚º0.2:  {np.mean(noise_stability[0.2])*100:.1f}%å®‰å®š
  â†’ ãƒã‚¤ã‚ºè€æ€§ãŒãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œçŸ¥ã®éµ

ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘
  1. ã‚¸ãƒƒã‚¿ãƒ¼é–¾å€¤ã«ã‚ˆã‚‹ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³åˆ†é¡å™¨ã®æ§‹ç¯‰
  2. Transformer/LLMã¸ã®é©ç”¨
  3. åŒæœŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹ã‚¯ãƒ©ã‚¹äºˆæ¸¬
  4. å®Ÿç”¨çš„ãªUI/APIã®é–‹ç™º
""")

print("\nğŸš€ SNN = ã€ŒAIã®å¿ƒé›»å›³ã€ï¼ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®é¼“å‹•ãŒè¦‹ãˆã‚‹ï¼")
print("=" * 70)
