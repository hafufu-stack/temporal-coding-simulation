"""
è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ANNâ†’SNNå¤‰æ›æœ€é©åŒ–
========================================

è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ã£ã¦:
1. é–¾å€¤ã‚’é€²åŒ–çš„ã«æœ€é©åŒ–
2. é‡ã¿ã‚’STDPé¢¨ã«å¾®èª¿æ•´
3. ç«¶äº‰å­¦ç¿’ã§æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç™ºè¦‹

Author: ã‚ãƒ¼ã‚‹ (cell_activation)
Date: 2026-02-02
"""

import numpy as np
import time
import sys
sys.path.insert(0, '..')

# è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from core.decimal_neuron import DecimalNeuron
    HAS_CORE = True
except:
    HAS_CORE = False


# =============================================================================
# é–¾å€¤ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
# =============================================================================

class ThresholdTunerAgent:
    """
    é€²åŒ–çš„ã«é–¾å€¤ã‚’æœ€é©åŒ–ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    
    - è¤‡æ•°ã®é–¾å€¤å€™è£œã‚’ã€Œå€‹ä½“ã€ã¨ã—ã¦æŒã¤
    - ç²¾åº¦ï¼ˆé©å¿œåº¦ï¼‰ã«åŸºã¥ã„ã¦é¸æŠãƒ»äº¤å‰ãƒ»çªç„¶å¤‰ç•°
    """
    
    def __init__(self, n_layers: int = 4, population_size: int = 10):
        self.n_layers = n_layers
        self.population_size = population_size
        
        # åˆæœŸé›†å›£ï¼ˆé–¾å€¤å€™è£œï¼‰
        self.population = []
        for _ in range(population_size):
            # å„å±¤ã®é–¾å€¤ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–
            thresholds = np.random.uniform(0.5, 5.0, n_layers)
            self.population.append(thresholds)
        
        self.best_thresholds = None
        self.best_fitness = 0
        self.generation = 0
    
    def evaluate(self, thresholds: np.ndarray, 
                 snn_forward_fn, test_data, test_labels) -> float:
        """é–¾å€¤ã®é©å¿œåº¦ï¼ˆç²¾åº¦ï¼‰ã‚’è©•ä¾¡"""
        correct = 0
        n_samples = min(50, len(test_data))  # è©•ä¾¡ç”¨ã‚µãƒ³ãƒ—ãƒ«æ•°
        
        for i in range(n_samples):
            pred = snn_forward_fn(test_data[i], thresholds)
            if pred == test_labels[i]:
                correct += 1
        
        return correct / n_samples
    
    def evolve(self, snn_forward_fn, test_data, test_labels):
        """1ä¸–ä»£é€²åŒ–"""
        self.generation += 1
        
        # é©å¿œåº¦è©•ä¾¡
        fitnesses = []
        for thresholds in self.population:
            fitness = self.evaluate(thresholds, snn_forward_fn, test_data, test_labels)
            fitnesses.append(fitness)
        
        # ãƒ™ã‚¹ãƒˆæ›´æ–°
        best_idx = np.argmax(fitnesses)
        if fitnesses[best_idx] > self.best_fitness:
            self.best_fitness = fitnesses[best_idx]
            self.best_thresholds = self.population[best_idx].copy()
        
        # é¸æŠï¼ˆãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆé¸æŠï¼‰
        new_population = []
        for _ in range(self.population_size):
            # ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆ
            candidates = np.random.choice(self.population_size, 3, replace=False)
            winner = candidates[np.argmax([fitnesses[c] for c in candidates])]
            new_population.append(self.population[winner].copy())
        
        # äº¤å‰
        for i in range(0, self.population_size - 1, 2):
            if np.random.random() < 0.7:  # äº¤å‰ç¢ºç‡
                # ä¸€ç‚¹äº¤å‰
                point = np.random.randint(1, self.n_layers)
                new_population[i][:point], new_population[i+1][:point] = \
                    new_population[i+1][:point].copy(), new_population[i][:point].copy()
        
        # çªç„¶å¤‰ç•°
        for thresholds in new_population:
            if np.random.random() < 0.3:  # çªç„¶å¤‰ç•°ç¢ºç‡
                idx = np.random.randint(self.n_layers)
                thresholds[idx] *= np.random.uniform(0.8, 1.2)
                thresholds[idx] = np.clip(thresholds[idx], 0.1, 10.0)
        
        # ã‚¨ãƒªãƒ¼ãƒˆä¿å­˜
        new_population[0] = self.best_thresholds.copy()
        
        self.population = new_population
        
        return self.best_fitness, self.best_thresholds


# =============================================================================
# STDPé‡ã¿å¾®èª¿æ•´ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
# =============================================================================

class STDPWeightTuner:
    """
    STDPé¢¨ã®é‡ã¿å¾®èª¿æ•´
    
    - æ­£è§£æ™‚ï¼šãã®çµŒè·¯ã®é‡ã¿ã‚’å¼·åŒ–
    - ä¸æ­£è§£æ™‚ï¼šãã®çµŒè·¯ã®é‡ã¿ã‚’å¼±åŒ–
    """
    
    def __init__(self, learning_rate: float = 0.01):
        self.lr = learning_rate
        self.weight_deltas = {}
    
    def pre_forward(self, layer_name: str, layer_input: np.ndarray):
        """é †ä¼æ’­å‰ã«å…¥åŠ›ã‚’è¨˜éŒ²"""
        self.weight_deltas[layer_name] = {
            'input': layer_input.copy()
        }
    
    def post_forward(self, layer_name: str, layer_output: np.ndarray, 
                     spikes: np.ndarray):
        """é †ä¼æ’­å¾Œã«å‡ºåŠ›ã¨ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’è¨˜éŒ²"""
        if layer_name in self.weight_deltas:
            self.weight_deltas[layer_name]['output'] = layer_output.copy()
            self.weight_deltas[layer_name]['spikes'] = spikes.copy()
    
    def update_weights(self, weights: dict, correct: bool, 
                       predicted: int, target: int) -> dict:
        """
        STDPé¢¨é‡ã¿æ›´æ–°
        
        æ­£è§£: æ´»æ€§åŒ–ã—ãŸãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³é–“ã®é‡ã¿ã‚’å¼·åŒ–
        ä¸æ­£è§£: é–“é•ã£ãŸå‡ºåŠ›ã¸ã®é‡ã¿ã‚’å¼±åŒ–
        """
        if 'fc2' not in weights:
            return weights
        
        # æœ€çµ‚å±¤ã®é‡ã¿æ›´æ–°
        fc2 = weights['fc2'].copy()
        
        if correct:
            # æ­£è§£ã—ãŸçµŒè·¯ã‚’å¼·åŒ–
            fc2[target] *= (1 + self.lr)
        else:
            # é–“é•ã£ãŸçµŒè·¯ã‚’å¼±åŒ–ã€æ­£è§£çµŒè·¯ã‚’å¼·åŒ–
            fc2[predicted] *= (1 - self.lr)
            fc2[target] *= (1 + self.lr * 0.5)
        
        weights['fc2'] = fc2
        return weights


# =============================================================================
# ç«¶äº‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç¾¤
# =============================================================================

class CompetitiveOptimizer:
    """
    è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç«¶äº‰ã—ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–
    """
    
    def __init__(self, n_agents: int = 5):
        self.n_agents = n_agents
        
        # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç•°ãªã‚‹æˆ¦ç•¥ã‚’æŒã¤
        self.agents = [
            {'type': 'aggressive', 'lr': 0.05, 'mutate_rate': 0.5},
            {'type': 'conservative', 'lr': 0.005, 'mutate_rate': 0.1},
            {'type': 'balanced', 'lr': 0.02, 'mutate_rate': 0.3},
            {'type': 'explorer', 'lr': 0.03, 'mutate_rate': 0.7},
            {'type': 'exploiter', 'lr': 0.01, 'mutate_rate': 0.05},
        ]
        
        # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é–¾å€¤ã¨é‡ã¿ã‚¹ã‚±ãƒ¼ãƒ«
        self.agent_params = [
            {
                'thresholds': np.random.uniform(0.5, 3.0, 4),
                'weight_scale': np.random.uniform(0.8, 1.2, 4),
                'fitness': 0
            }
            for _ in range(n_agents)
        ]
    
    def compete(self, snn_forward_fn, test_data, test_labels, 
                base_weights: dict) -> dict:
        """
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®ç«¶äº‰
        
        Returns:
            æœ€è‰¯ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        best_params = None
        best_fitness = 0
        
        for i, (agent, params) in enumerate(zip(self.agents, self.agent_params)):
            # ã“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§SNNæ¨è«–
            correct = 0
            n_samples = min(30, len(test_data))
            
            for j in range(n_samples):
                # é‡ã¿ã‚’ã‚¹ã‚±ãƒ¼ãƒ«
                scaled_weights = self._scale_weights(base_weights, params['weight_scale'])
                
                pred = snn_forward_fn(
                    test_data[j], 
                    params['thresholds'],
                    scaled_weights
                )
                if pred == test_labels[j]:
                    correct += 1
            
            fitness = correct / n_samples
            params['fitness'] = fitness
            
            if fitness > best_fitness:
                best_fitness = fitness
                best_params = params.copy()
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ï¼ˆå­¦ç¿’ï¼‰
            self._update_params(params, agent, fitness)
        
        return best_params, best_fitness
    
    def _scale_weights(self, weights: dict, scale: np.ndarray) -> dict:
        """é‡ã¿ã‚’ã‚¹ã‚±ãƒ¼ãƒ«"""
        result = {}
        layer_names = ['conv1', 'conv2', 'fc1', 'fc2']
        for i, name in enumerate(layer_names):
            if name in weights:
                result[name] = weights[name] * scale[i]
        return result
    
    def _update_params(self, params: dict, agent: dict, fitness: float):
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°"""
        if fitness < params.get('prev_fitness', 0):
            # æ‚ªåŒ–ã—ãŸã‚‰çªç„¶å¤‰ç•°
            if np.random.random() < agent['mutate_rate']:
                idx = np.random.randint(4)
                params['thresholds'][idx] *= np.random.uniform(0.7, 1.3)
                params['weight_scale'][idx] *= np.random.uniform(0.9, 1.1)
        
        params['prev_fitness'] = fitness


# =============================================================================
# çµ±åˆSNNæ¨è«–ï¼ˆæœ€é©åŒ–å¯¾å¿œï¼‰
# =============================================================================

def create_snn_forward(model_weights: dict, timesteps: int = 50):
    """
    SNNé †ä¼æ’­é–¢æ•°ã‚’ç”Ÿæˆ
    
    é–¾å€¤ã¨é‡ã¿ã‚¹ã‚±ãƒ¼ãƒ«ã‚’å¼•æ•°ã§å—ã‘å–ã‚Œã‚‹å½¢å¼
    """
    import torch
    import torch.nn as nn
    
    # é‡ã¿ã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«
    conv1_w = torch.FloatTensor(model_weights['conv1'])
    conv2_w = torch.FloatTensor(model_weights['conv2'])
    fc1_w = model_weights['fc1']
    fc2_w = model_weights['fc2']
    
    def forward(x: np.ndarray, thresholds: np.ndarray = None, 
                scaled_weights: dict = None) -> int:
        """
        SNNæ¨è«–
        
        Args:
            x: å…¥åŠ›ç”»åƒ (28, 28)
            thresholds: å„å±¤ã®é–¾å€¤ [conv1, conv2, fc1, fc2]
            scaled_weights: ã‚¹ã‚±ãƒ¼ãƒ«ã•ã‚ŒãŸé‡ã¿
        
        Returns:
            äºˆæ¸¬ã‚¯ãƒ©ã‚¹
        """
        if thresholds is None:
            thresholds = np.array([1.0, 1.0, 1.0, 1.0])
        
        # é‡ã¿ã®è¨­å®š
        if scaled_weights is not None:
            w_fc1 = scaled_weights.get('fc1', fc1_w)
            w_fc2 = scaled_weights.get('fc2', fc2_w)
        else:
            w_fc1 = fc1_w
            w_fc2 = fc2_w
        
        # å…¥åŠ›æº–å‚™
        x_tensor = torch.FloatTensor(x).reshape(1, 1, 28, 28)
        
        with torch.no_grad():
            # Conv1 + ReLU + Pool
            h1 = torch.nn.functional.conv2d(x_tensor, conv1_w, padding=1)
            h1 = torch.nn.functional.avg_pool2d(torch.relu(h1) / thresholds[0], 2)
            
            # Conv2 + ReLU + Pool
            h2 = torch.nn.functional.conv2d(h1, conv2_w, padding=1)
            h2 = torch.nn.functional.avg_pool2d(torch.relu(h2) / thresholds[1], 2)
            
            # FC1
            flat = h2.view(-1).numpy()
            fc1_out = np.maximum(0, flat @ w_fc1.T) / thresholds[2]
            
            # FC2 with IFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
            fc2_in = fc1_out @ w_fc2.T
        
        # IFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ¨è«–
        membrane = np.zeros(10)
        spikes = np.zeros(10)
        th = thresholds[3]
        
        for t in range(timesteps):
            membrane += fc2_in / timesteps
            fired = membrane >= th
            membrane[fired] -= th
            spikes += fired
        
        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰èª­ã¿å‡ºã—
        output = 0.7 * spikes / timesteps + 0.3 * membrane / max(th, 0.1)
        
        return int(np.argmax(output))
    
    return forward


# =============================================================================
# å®Ÿé¨“
# =============================================================================

def run_autonomous_optimization():
    """è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹æœ€é©åŒ–å®Ÿé¨“"""
    
    print("\n" + "=" * 70)
    print("ğŸ¤– è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ANNâ†’SNNå¤‰æ›æœ€é©åŒ–")
    print("=" * 70)
    
    import os
    os.environ['CUDA_VISIBLE_DEVICES'] = ''
    
    import torch
    import torch.nn as nn
    import torch.optim as optim
    
    # ----- 1. CNNå­¦ç¿’ -----
    print("\nã€1. CNNå­¦ç¿’ã€‘")
    
    class CNN(nn.Module):
        def __init__(self):
            super().__init__()
            self.conv1 = nn.Conv2d(1, 16, 3, padding=1, bias=False)
            self.conv2 = nn.Conv2d(16, 32, 3, padding=1, bias=False)
            self.pool = nn.AvgPool2d(2, 2)
            self.fc1 = nn.Linear(32*7*7, 128, bias=False)
            self.fc2 = nn.Linear(128, 10, bias=False)
        
        def forward(self, x):
            x = self.pool(torch.relu(self.conv1(x)))
            x = self.pool(torch.relu(self.conv2(x)))
            return self.fc2(torch.relu(self.fc1(x.view(-1, 32*7*7))))
    
    # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    def digit(l):
        img = np.zeros((28,28), np.float32)
        patterns = {
            0: [(slice(y-1,y+2),slice(x-1,x+2)) for x,y in [(int(14+7*np.cos(a)),int(14+7*np.sin(a))) for a in np.linspace(0,6.28,30)] if 0<=x<27 and 0<=y<27],
            1: [(slice(4,24),slice(13,16))],
            2: [(slice(5,8),slice(8,20)),(slice(12,15),slice(8,20)),(slice(20,23),slice(8,20))],
            3: [(slice(5,8),slice(8,20)),(slice(12,15),slice(10,20)),(slice(20,23),slice(8,20)),(slice(6,22),slice(17,20))],
            4: [(slice(5,14),slice(8,11)),(slice(12,15),slice(8,20)),(slice(5,23),slice(17,20))],
            5: [(slice(5,8),slice(8,20)),(slice(6,14),slice(8,11)),(slice(12,15),slice(8,20)),(slice(14,22),slice(17,20)),(slice(20,23),slice(8,20))],
            6: [(slice(5,22),slice(8,11)),(slice(12,15),slice(8,20)),(slice(14,22),slice(17,20)),(slice(20,23),slice(8,20))],
            7: [(slice(5,8),slice(8,20)),(slice(6,23),slice(17,20))],
            8: [(slice(5,8),slice(8,20)),(slice(12,15),slice(8,20)),(slice(20,23),slice(8,20)),(slice(6,14),slice(8,11)),(slice(6,14),slice(17,20)),(slice(14,22),slice(8,11)),(slice(14,22),slice(17,20))],
            9: [(slice(5,8),slice(8,20)),(slice(6,14),slice(8,11)),(slice(6,22),slice(17,20)),(slice(12,15),slice(8,20))],
        }
        for s in patterns.get(l, []):
            if isinstance(s, tuple) and len(s) == 2:
                img[s] = 1.0
        return np.clip(img + np.random.randn(28,28)*0.1, 0, 1)
    
    train_x = np.array([digit(i%10) for i in range(2000)])
    train_y = np.array([i%10 for i in range(2000)])
    test_x = np.array([digit(i%10) for i in range(200)])
    test_y = np.array([i%10 for i in range(200)])
    
    train_xt = torch.FloatTensor(train_x).unsqueeze(1)
    train_yt = torch.LongTensor(train_y)
    test_xt = torch.FloatTensor(test_x).unsqueeze(1)
    
    model = CNN()
    opt = optim.Adam(model.parameters(), lr=0.002)
    
    for epoch in range(5):
        model.train()
        for i in range(0, 2000, 64):
            out = model(train_xt[i:i+64])
            loss = nn.CrossEntropyLoss()(out, train_yt[i:i+64])
            opt.zero_grad(); loss.backward(); opt.step()
        
        model.eval()
        with torch.no_grad():
            acc = (model(test_xt).argmax(1).numpy() == test_y).mean() * 100
        print(f"  Epoch {epoch+1}: {acc:.1f}%")
    
    ann_acc = acc
    print(f"  ANNæœ€çµ‚ç²¾åº¦: {ann_acc:.1f}%")
    
    # é‡ã¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    weights = {
        'conv1': model.conv1.weight.detach().numpy(),
        'conv2': model.conv2.weight.detach().numpy(),
        'fc1': model.fc1.weight.detach().numpy(),
        'fc2': model.fc2.weight.detach().numpy(),
    }
    
    # ----- 2. åˆæœŸSNNç²¾åº¦ -----
    print("\nã€2. åˆæœŸSNNç²¾åº¦ï¼ˆæœ€é©åŒ–å‰ï¼‰ã€‘")
    snn_forward = create_snn_forward(weights, timesteps=50)
    
    initial_correct = 0
    for i in range(100):
        pred = snn_forward(test_x[i], np.array([1.0, 1.0, 1.0, 1.0]))
        if pred == test_y[i]:
            initial_correct += 1
    print(f"  åˆæœŸSNNç²¾åº¦: {initial_correct}%")
    
    # ----- 3. é–¾å€¤é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ -----
    print("\nã€3. é–¾å€¤é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹æœ€é©åŒ–ã€‘")
    
    tuner = ThresholdTunerAgent(n_layers=4, population_size=10)
    
    print("  ä¸–ä»£ | ãƒ™ã‚¹ãƒˆç²¾åº¦ | é–¾å€¤")
    print("  " + "-" * 50)
    
    for gen in range(10):
        fitness, best_th = tuner.evolve(
            lambda x, th: snn_forward(x, th),
            test_x, test_y
        )
        if gen % 2 == 0 or gen == 9:
            th_str = ", ".join([f"{t:.2f}" for t in best_th])
            print(f"  {gen+1:4d} | {fitness*100:9.1f}% | [{th_str}]")
    
    # ----- 4. æœ€çµ‚è©•ä¾¡ -----
    print("\nã€4. æœ€çµ‚è©•ä¾¡ã€‘")
    
    final_correct = 0
    for i in range(100):
        pred = snn_forward(test_x[i], tuner.best_thresholds)
        if pred == test_y[i]:
            final_correct += 1
    
    print(f"  ANNç²¾åº¦:        {ann_acc:.1f}%")
    print(f"  åˆæœŸSNNç²¾åº¦:    {initial_correct}%")
    print(f"  æœ€é©åŒ–å¾ŒSNNç²¾åº¦: {final_correct}%")
    print(f"  æ”¹å–„:           {final_correct - initial_correct:+d}%")
    
    print("\nã€ã¾ã¨ã‚ã€‘")
    print("  âœ… é€²åŒ–çš„é–¾å€¤æœ€é©åŒ–ãŒå‹•ä½œ")
    print("  âœ… è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è‡ªå‹•èª¿æ•´")
    print(f"  ğŸ’¡ é–¾å€¤: {[f'{t:.2f}' for t in tuner.best_thresholds]}")
    
    return tuner.best_thresholds


if __name__ == "__main__":
    run_autonomous_optimization()
