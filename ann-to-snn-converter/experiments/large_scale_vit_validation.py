"""
å¤§è¦æ¨¡æ¤œè¨¼: ViT-Base + ImageNeté¢¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
==============================================

ã‚ˆã‚Šå¤§ããªViTãƒ¢ãƒ‡ãƒ«ã§SNNãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œçŸ¥ã‚’æ¤œè¨¼ã€‚
CIFAR-100ã‚„Tiny ImageNetã‚’ä½¿ç”¨ã€‚

Author: ã‚ãƒ¼ã‚‹ (Cell Activation)
Date: 2026-02-04
"""

import os
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict
import math
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['font.family'] = ['MS Gothic', 'DejaVu Sans']

print("=" * 70)
print("ğŸ“Š å¤§è¦æ¨¡æ¤œè¨¼: ViT-Base + CIFAR-100")
print("=" * 70)


# =============================================================================
# 1. å¤§è¦æ¨¡ViTãƒ¢ãƒ‡ãƒ«
# =============================================================================
class MultiHeadAttention(nn.Module):
    def __init__(self, d_model, num_heads, dropout=0.1):
        super().__init__()
        self.d_model = d_model
        self.num_heads = num_heads
        self.head_dim = d_model // num_heads
        
        self.q_proj = nn.Linear(d_model, d_model)
        self.k_proj = nn.Linear(d_model, d_model)
        self.v_proj = nn.Linear(d_model, d_model)
        self.out_proj = nn.Linear(d_model, d_model)
        self.dropout = nn.Dropout(dropout)
        
        self.attention_weights = None
    
    def forward(self, x):
        B, N, C = x.shape
        
        q = self.q_proj(x).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)
        k = self.k_proj(x).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)
        v = self.v_proj(x).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)
        
        attn = (q @ k.transpose(-2, -1)) / math.sqrt(self.head_dim)
        attn = F.softmax(attn, dim=-1)
        attn = self.dropout(attn)
        self.attention_weights = attn.detach()
        
        out = (attn @ v).transpose(1, 2).reshape(B, N, C)
        return self.out_proj(out)


class TransformerBlock(nn.Module):
    def __init__(self, d_model, num_heads, mlp_ratio=4.0, dropout=0.1):
        super().__init__()
        self.norm1 = nn.LayerNorm(d_model)
        self.attn = MultiHeadAttention(d_model, num_heads, dropout)
        self.norm2 = nn.LayerNorm(d_model)
        self.mlp = nn.Sequential(
            nn.Linear(d_model, int(d_model * mlp_ratio)),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(int(d_model * mlp_ratio), d_model),
            nn.Dropout(dropout)
        )
        self.post_attn = None
        self.post_mlp = None
    
    def forward(self, x):
        attn_out = self.attn(self.norm1(x))
        x = x + attn_out
        self.post_attn = x.detach()
        
        mlp_out = self.mlp(self.norm2(x))
        x = x + mlp_out
        self.post_mlp = x.detach()
        
        return x


class ViTBase(nn.Module):
    """ViT-Baseé¢¨ãƒ¢ãƒ‡ãƒ« (ç¸®å°ç‰ˆ)"""
    def __init__(self, img_size=32, patch_size=4, in_chans=3, num_classes=100,
                 d_model=256, depth=8, num_heads=8, dropout=0.1):
        super().__init__()
        self.patch_size = patch_size
        num_patches = (img_size // patch_size) ** 2
        
        self.patch_embed = nn.Conv2d(in_chans, d_model, kernel_size=patch_size, stride=patch_size)
        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))
        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, d_model))
        self.pos_drop = nn.Dropout(dropout)
        
        self.blocks = nn.ModuleList([
            TransformerBlock(d_model, num_heads, dropout=dropout) for _ in range(depth)
        ])
        
        self.norm = nn.LayerNorm(d_model)
        self.head = nn.Linear(d_model, num_classes)
        
        nn.init.normal_(self.pos_embed, std=0.02)
        nn.init.normal_(self.cls_token, std=0.02)
    
    def forward(self, x):
        B = x.shape[0]
        
        x = self.patch_embed(x)
        x = x.flatten(2).transpose(1, 2)
        
        cls_tokens = self.cls_token.expand(B, -1, -1)
        x = torch.cat([cls_tokens, x], dim=1)
        x = self.pos_drop(x + self.pos_embed)
        
        for block in self.blocks:
            x = block(x)
        
        x = self.norm(x)
        return self.head(x[:, 0])
    
    def get_all_activations(self):
        activations = {}
        for i, block in enumerate(self.blocks):
            activations[f'block{i}_attn'] = block.post_attn
            activations[f'block{i}_mlp'] = block.post_mlp
            activations[f'block{i}_attn_weights'] = block.attn.attention_weights
        return activations


# =============================================================================
# 2. SNNç‰¹å¾´é‡æŠ½å‡ºå™¨
# =============================================================================
class LargeScaleSNNAnalyzer:
    def __init__(self, timesteps=100, num_trials=5):
        self.timesteps = timesteps
        self.num_trials = num_trials
    
    def compute_ttfs(self, activation):
        ttfs = torch.full_like(activation, float(self.timesteps))
        active_mask = activation > 0
        if active_mask.any():
            max_act = activation.max()
            if max_act > 0:
                normalized = activation[active_mask] / max_act
                ttfs[active_mask] = self.timesteps * (1 - normalized)
        return ttfs
    
    def extract_features(self, model, x, noise_std=0.05):
        features = {}
        
        model.eval()
        with torch.no_grad():
            output = model(x)
            probs = F.softmax(output, dim=1)
            
            features['confidence'] = probs.max().item()
            features['entropy'] = -(probs * torch.log(probs + 1e-8)).sum().item()
            features['margin'] = (probs.topk(2)[0][0,0] - probs.topk(2)[0][0,1]).item()
            
            activations = model.get_all_activations()
            
            for name, act in activations.items():
                if act is None:
                    continue
                if 'attn_weights' in name:
                    # Attentioné‡ã¿è§£æ
                    attn = act
                    features[f'{name}_entropy'] = -(attn * torch.log(attn + 1e-8)).sum(dim=-1).mean().item()
                else:
                    # éš ã‚ŒçŠ¶æ…‹è§£æ
                    ttfs = self.compute_ttfs(act)
                    features[f'{name}_ttfs_mean'] = ttfs.mean().item()
                    features[f'{name}_act_std'] = act.std().item()
            
            # ã‚¸ãƒƒã‚¿ãƒ¼è¨ˆç®—
            outputs = []
            for _ in range(self.num_trials):
                noisy_x = x + torch.randn_like(x) * noise_std
                noisy_x = torch.clamp(noisy_x, 0, 1)
                outputs.append(model(noisy_x))
            
            stacked = torch.stack(outputs)
            features['output_jitter'] = stacked.std(dim=0).mean().item()
            
            preds = [o.argmax(dim=1).item() for o in outputs]
            features['pred_stability'] = 1 if len(set(preds)) == 1 else len(set(preds)) / len(preds)
        
        return features


# =============================================================================
# 3. ãƒ‡ãƒ¼ã‚¿æº–å‚™ (CIFAR-100)
# =============================================================================
print("\nã€1. CIFAR-100ãƒ‡ãƒ¼ã‚¿æº–å‚™ã€‘")
from torchvision import datasets, transforms

transform_train = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(32, padding=4),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)
test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)

# ã‚µãƒ–ã‚»ãƒƒãƒˆä½¿ç”¨
train_subset = torch.utils.data.Subset(train_dataset, range(10000))
test_subset = torch.utils.data.Subset(test_dataset, range(500))

train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_subset, batch_size=1, shuffle=False)

print(f"  è¨“ç·´: {len(train_subset)}, ãƒ†ã‚¹ãƒˆ: {len(test_subset)}")
print(f"  ã‚¯ãƒ©ã‚¹æ•°: 100")


# =============================================================================
# 4. ViT-Baseå­¦ç¿’
# =============================================================================
print("\nã€2. ViT-Baseå­¦ç¿’ã€‘")

model = ViTBase(
    img_size=32, patch_size=4, in_chans=3, num_classes=100,
    d_model=256, depth=8, num_heads=8, dropout=0.1
)

param_count = sum(p.numel() for p in model.parameters())
print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {param_count:,}")

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.05)

epochs = 15
for epoch in range(epochs):
    model.train()
    for data, target in train_loader:
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
    
    if (epoch + 1) % 5 == 0:
        model.eval()
        correct = 0
        with torch.no_grad():
            for data, target in test_loader:
                pred = model(data).argmax(dim=1)
                correct += (pred == target).sum().item()
        print(f"  Epoch {epoch+1}: Accuracy = {100*correct/len(test_subset):.1f}%")

print(f"\n  ViT-Baseå­¦ç¿’å®Œäº†ï¼")


# =============================================================================
# 5. ç‰¹å¾´é‡æŠ½å‡º & ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œçŸ¥
# =============================================================================
print("\nã€3. ç‰¹å¾´é‡æŠ½å‡º & ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œçŸ¥ã€‘")

from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, classification_report

analyzer = LargeScaleSNNAnalyzer(timesteps=100, num_trials=5)

X_data = []
y_data = []

model.eval()
for i, (data, target) in enumerate(test_loader):
    if i >= 300:
        break
    
    features = analyzer.extract_features(model, data)
    X_data.append(list(features.values()))
    
    with torch.no_grad():
        pred = model(data).argmax(dim=1).item()
    y_data.append(0 if pred == target.item() else 1)
    
    if (i + 1) % 100 == 0:
        print(f"  æŠ½å‡º: {i+1}/300")

X_data = np.array(X_data)
y_data = np.array(y_data)

print(f"\n  ç‰¹å¾´é‡æ•°: {X_data.shape[1]}")
print(f"  æ­£è§£: {sum(1 for y in y_data if y == 0)}, ä¸æ­£è§£: {sum(1 for y in y_data if y == 1)}")

# åˆ†å‰²
split = 200
X_train, X_val = X_data[:split], X_data[split:]
y_train, y_val = y_data[:split], y_data[split:]

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)
clf.fit(X_train_scaled, y_train)

y_pred = clf.predict(X_val_scaled)
y_prob = clf.predict_proba(X_val_scaled)[:, 1]

print(f"\n  ã€æ¤œè¨¼çµæœã€‘")
print(classification_report(y_val, y_pred, target_names=['Correct', 'Wrong'], zero_division=0))

if len(set(y_val)) > 1:
    auc = roc_auc_score(y_val, y_prob)
    print(f"  AUC-ROC: {auc:.4f}")
else:
    auc = 0.5

# ç‰¹å¾´é‡é‡è¦åº¦
feature_names = list(features.keys())
importances = clf.feature_importances_
indices = np.argsort(importances)[::-1]

print(f"\n  ã€Top 10 é‡è¦ç‰¹å¾´é‡ã€‘")
for i in range(min(10, len(feature_names))):
    idx = indices[i]
    print(f"    {i+1}. {feature_names[idx]}: {importances[idx]:.4f}")


# =============================================================================
# 6. å¯è¦–åŒ–
# =============================================================================
print("\nã€4. å¯è¦–åŒ–ã€‘")

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# ROCæ›²ç·š
ax = axes[0, 0]
if len(set(y_val)) > 1:
    from sklearn.metrics import roc_curve
    fpr, tpr, _ = roc_curve(y_val, y_prob)
    ax.plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC={auc:.3f}')
    ax.plot([0, 1], [0, 1], 'k--', alpha=0.5)
    ax.set_xlabel('False Positive Rate')
    ax.set_ylabel('True Positive Rate')
    ax.set_title('ROC Curve (ViT-Base, CIFAR-100)')
    ax.legend()

# ç‰¹å¾´é‡é‡è¦åº¦
ax = axes[0, 1]
top_n = 10
top_idx = indices[:top_n]
top_names = [feature_names[i][:20] for i in top_idx]
top_imp = importances[top_idx]
ax.barh(range(top_n), top_imp, color='steelblue')
ax.set_yticks(range(top_n))
ax.set_yticklabels(top_names)
ax.set_xlabel('Importance')
ax.set_title('Top 10 Feature Importances')
ax.invert_yaxis()

# ç¢ºä¿¡åº¦åˆ†å¸ƒ
ax = axes[1, 0]
correct_conf = [X_data[i, 0] for i in range(len(y_data)) if y_data[i] == 0]
wrong_conf = [X_data[i, 0] for i in range(len(y_data)) if y_data[i] == 1]
ax.hist(correct_conf, bins=15, alpha=0.7, label='Correct', color='green')
ax.hist(wrong_conf, bins=15, alpha=0.7, label='Wrong', color='red')
ax.set_xlabel('Confidence')
ax.set_title('Confidence Distribution')
ax.legend()

# ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ç¢ºç‡åˆ†å¸ƒ
ax = axes[1, 1]
correct_prob = [y_prob[i] for i in range(len(y_val)) if y_val[i] == 0]
wrong_prob = [y_prob[i] for i in range(len(y_val)) if y_val[i] == 1]
ax.hist(correct_prob, bins=15, alpha=0.7, label='Correct', color='green')
ax.hist(wrong_prob, bins=15, alpha=0.7, label='Wrong', color='red')
ax.set_xlabel('Hallucination Probability')
ax.set_title('Predicted Hallucination Probability')
ax.legend()

plt.tight_layout()
plt.savefig('vit_base_cifar100_analysis.png', dpi=150, bbox_inches='tight')
print("  ä¿å­˜: vit_base_cifar100_analysis.png")


# =============================================================================
# 7. ã¾ã¨ã‚
# =============================================================================
print("\n" + "=" * 70)
print("ğŸ“Š å¤§è¦æ¨¡æ¤œè¨¼ ã¾ã¨ã‚")
print("=" * 70)

print(f"""
ã€ãƒ¢ãƒ‡ãƒ«ã€‘
  - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: ViT-Base (8å±¤, 8ãƒ˜ãƒƒãƒ‰, 256æ¬¡å…ƒ)
  - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {param_count:,}
  - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: CIFAR-100 (100ã‚¯ãƒ©ã‚¹)

ã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œçŸ¥çµæœã€‘
  - ç‰¹å¾´é‡æ•°: {len(feature_names)}
  - AUC-ROC: {auc:.4f}

ã€é‡è¦ç‰¹å¾´é‡ã€‘
  1. {feature_names[indices[0]]}: {importances[indices[0]]:.4f}
  2. {feature_names[indices[1]]}: {importances[indices[1]]:.4f}
  3. {feature_names[indices[2]]}: {importances[indices[2]]:.4f}

ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ç¢ºèªã€‘
  - ViT-Baseãƒ¬ãƒ™ãƒ«ã§ã‚‚ SNNç‰¹å¾´é‡æŠ½å‡ºãŒæ©Ÿèƒ½
  - CIFAR-100 (100ã‚¯ãƒ©ã‚¹) ã§ã‚‚ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œçŸ¥ãŒå¯èƒ½
  - ã‚ˆã‚Šå¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®é©ç”¨ã‚‚æœŸå¾…

ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘
  - ImageNet-1k ã§ã®æ¤œè¨¼
  - ViT-Large/Huge ã¸ã®æ‹¡å¼µ
  - å®Ÿä¸–ç•Œã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®ãƒ†ã‚¹ãƒˆ
""")

print("\nğŸš€ å¤§è¦æ¨¡ViTã§ã‚‚SNNè§£æãŒæœ‰åŠ¹ï¼")
print("=" * 70)
