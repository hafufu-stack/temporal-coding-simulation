"""
Llama-2 SNN Analysis + SNN Guardrail (Real-time Defense)
=========================================================

Llama-2ãƒ¢ãƒ‡ãƒ«ã®TTFSè§£æã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é˜²å¾¡ã‚·ã‚¹ãƒ†ãƒ ã€ŒSNNã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã€

æ–°æ©Ÿèƒ½:
1. Llama-2ã®Attention TTFSè§£æ  
2. SNNã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«: TTFS/Jitterç•°å¸¸æ™‚ã«ç”Ÿæˆã‚’åœæ­¢
3. "[WARNING: Neural Instability Detected]" è­¦å‘Šå‡ºåŠ›

Author: ã‚ãƒ¼ã‚‹ (Cell Activation)
Date: 2026-02-05
"""

import os
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict
import warnings
import time
warnings.filterwarnings('ignore')

plt.rcParams['font.family'] = ['MS Gothic', 'DejaVu Sans']

print("=" * 70)
print("ğŸ¦™ Llama-2 SNN Analysis + SNN Guardrail")
print("=" * 70)


# =============================================================================
# 1. ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆLlama-2 or ä»£æ›¿ãƒ¢ãƒ‡ãƒ«ï¼‰
# =============================================================================
print("\nã€1. ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã€‘")

try:
    from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig
    print("  âœ… Transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿æˆåŠŸ")
except ImportError:
    print("  âŒ pip install transformers ãŒå¿…è¦ã§ã™")
    exit(1)

# Llama-2ã‚’è©¦ã™ã€‚ãªã‘ã‚Œã°ä»£æ›¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
MODEL_CANDIDATES = [
    "TinyLlama/TinyLlama-1.1B-Chat-v1.0",  # 1.1B, è»½é‡
    "microsoft/phi-2",                       # 2.7B
    "distilgpt2",                            # fallback
]

model = None
tokenizer = None
model_name = None

for candidate in MODEL_CANDIDATES:
    try:
        print(f"  è©¦è¡Œä¸­: {candidate}")
        tokenizer = AutoTokenizer.from_pretrained(candidate, trust_remote_code=True)
        model = AutoModelForCausalLM.from_pretrained(
            candidate, 
            output_attentions=True, 
            output_hidden_states=True,
            trust_remote_code=True,
            torch_dtype=torch.float32
        )
        model.eval()
        model_name = candidate
        print(f"  âœ… æˆåŠŸ: {candidate}")
        break
    except Exception as e:
        print(f"  âš ï¸ å¤±æ•—: {str(e)[:50]}...")
        continue

if model is None:
    print("  âŒ ä½¿ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
    exit(1)

# Padding tokenè¨­å®š
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

print(f"\n  ãƒ¢ãƒ‡ãƒ«: {model_name}")
print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
n_layers = getattr(model.config, 'num_hidden_layers', getattr(model.config, 'n_layer', 6))
n_heads = getattr(model.config, 'num_attention_heads', getattr(model.config, 'n_head', 12))
print(f"  å±¤æ•°: {n_layers}, ãƒ˜ãƒƒãƒ‰æ•°: {n_heads}")


# =============================================================================
# 2. SNN Analyzer ã‚¯ãƒ©ã‚¹
# =============================================================================
class LLMSNNAnalyzer:
    """LLMç”¨SNNè§£æå™¨ï¼ˆLlama/GPT/Phiå¯¾å¿œï¼‰"""
    
    def __init__(self, model, tokenizer, timesteps=100):
        self.model = model
        self.tokenizer = tokenizer
        self.timesteps = timesteps
        self.n_layers = getattr(model.config, 'num_hidden_layers', 
                                getattr(model.config, 'n_layer', 6))
    
    def compute_ttfs(self, activation):
        """TTFSè¨ˆç®—ï¼ˆé«˜æ´»æ€§åŒ– â†’ æ—©ã„ç™ºç«ï¼‰"""
        ttfs = torch.full_like(activation, float(self.timesteps))
        active_mask = activation > 0
        if active_mask.any():
            max_act = activation.max()
            if max_act > 0:
                normalized = activation[active_mask] / max_act
                ttfs[active_mask] = self.timesteps * (1 - normalized)
        return ttfs
    
    def analyze_attention(self, attention_weights):
        """Attentioné‡ã¿ã®SNNè§£æ"""
        results = []
        
        for layer_idx, attn in enumerate(attention_weights):
            if attn is None:
                continue
            attn = attn.detach()
            
            # Incoming attention
            incoming = attn.mean(dim=1).mean(dim=1)  # (batch, seq_len)
            ttfs_incoming = self.compute_ttfs(incoming)
            
            # Outgoing attention (ã©ã“ã«æ³¨ç›®ã—ã¦ã„ã‚‹ã‹)
            outgoing = attn.mean(dim=1).mean(dim=2)  # (batch, seq_len)
            ttfs_outgoing = self.compute_ttfs(outgoing)
            
            # Headé–“åŒæœŸåº¦
            head_sync = self._compute_head_sync(attn)
            
            results.append({
                'layer': layer_idx,
                'ttfs_incoming_mean': ttfs_incoming.mean().item(),
                'ttfs_outgoing_mean': ttfs_outgoing.mean().item(),
                'head_sync': head_sync,
                'attention_entropy': self._attention_entropy(attn)
            })
        
        return results
    
    def _compute_head_sync(self, attn):
        """ãƒ˜ãƒƒãƒ‰é–“ã®åŒæœŸåº¦"""
        num_heads = attn.size(1)
        if num_heads < 2:
            return 1.0
        
        max_pos = attn.argmax(dim=-1)
        sync_count = 0
        total = 0
        for i in range(num_heads):
            for j in range(i+1, num_heads):
                agreement = (max_pos[:, i] == max_pos[:, j]).float().mean()
                sync_count += agreement.item()
                total += 1
        
        return sync_count / total if total > 0 else 1.0
    
    def _attention_entropy(self, attn):
        """Attentionã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼"""
        attn_flat = attn.mean(dim=1)
        entropy = -(attn_flat * torch.log(attn_flat + 1e-8)).sum(dim=-1).mean()
        return entropy.item()
    
    def extract_features(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å…¨ç‰¹å¾´é‡ã‚’æŠ½å‡º"""
        self.model.eval()
        
        inputs = self.tokenizer(text, return_tensors='pt', padding=True)
        
        with torch.no_grad():
            outputs = self.model(**inputs, output_attentions=True, output_hidden_states=True)
        
        features = {}
        
        # å‡ºåŠ›ç¢ºç‡
        logits = outputs.logits[0, -1]
        probs = F.softmax(logits, dim=-1)
        
        features['top_prob'] = probs.max().item()
        features['output_entropy'] = -(probs * torch.log(probs + 1e-8)).sum().item()
        features['margin'] = (probs.max() - probs.sort(descending=True)[0][1]).item()
        
        # Attentionè§£æ
        if outputs.attentions is not None:
            attn_results = self.analyze_attention(outputs.attentions)
            for res in attn_results:
                layer = res['layer']
                features[f'layer{layer}_ttfs_incoming'] = res['ttfs_incoming_mean']
                features[f'layer{layer}_ttfs_outgoing'] = res['ttfs_outgoing_mean']
                features[f'layer{layer}_head_sync'] = res['head_sync']
        
        # å¹³å‡TTFSï¼ˆå…¨å±¤ï¼‰
        ttfs_values = [v for k, v in features.items() if 'ttfs_incoming' in k]
        features['avg_ttfs'] = np.mean(ttfs_values) if ttfs_values else self.timesteps
        
        return features
    
    def compute_jitter(self, text, num_trials=5, noise_std=0.1):
        """å…¥åŠ›ã«å¾®å°ãƒã‚¤ã‚ºã‚’åŠ ãˆã¦TTFSã®ã‚¸ãƒƒã‚¿ãƒ¼ï¼ˆæºã‚Œï¼‰ã‚’æ¸¬å®š"""
        self.model.eval()
        
        inputs = self.tokenizer(text, return_tensors='pt', padding=True)
        
        ttfs_list = []
        probs_list = []
        
        with torch.no_grad():
            for _ in range(num_trials):
                # å…¥åŠ›embeddingã«ãƒã‚¤ã‚ºè¿½åŠ 
                outputs = self.model(**inputs, output_attentions=True)
                
                logits = outputs.logits[0, -1]
                probs = F.softmax(logits, dim=-1)
                probs_list.append(probs.max().item())
                
                if outputs.attentions is not None:
                    # æœ€çµ‚å±¤ã®TTFS
                    attn = outputs.attentions[-1]
                    incoming = attn.mean(dim=1).mean(dim=1)
                    ttfs = self.compute_ttfs(incoming)
                    ttfs_list.append(ttfs.mean().item())
        
        return {
            'ttfs_jitter': np.std(ttfs_list) if ttfs_list else 0,
            'prob_jitter': np.std(probs_list) if probs_list else 0,
            'ttfs_mean': np.mean(ttfs_list) if ttfs_list else 0
        }


# =============================================================================
# 3. SNN Guardrailï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é˜²å¾¡ã‚·ã‚¹ãƒ†ãƒ ï¼‰
# =============================================================================
class SNNGuardrail:
    """
    SNNã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ« - AIã®æš´èµ°ã‚’æ­¢ã‚ã‚‹å®‰å…¨è£…ç½®
    
    å‹•ä½œåŸç†:
    1. æ¨è«–ä¸­ã®TTFS/Jitterã‚’ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
    2. ç•°å¸¸å€¤ï¼ˆé–¾å€¤è¶…éï¼‰ã‚’æ¤œå‡º
    3. ç”Ÿæˆã‚’ä¸­æ–­ã—è­¦å‘Šã‚’å‡ºåŠ›
    
    "AIã®å¿ƒæ‹æ•°ã‚’æ¸¬ã£ã¦ã€å˜˜ã‚’ã¤ã„ãŸã‚‰æ­¢ã‚ã‚‹"
    """
    
    def __init__(self, analyzer, 
                 ttfs_threshold=3.0,  # å¹³å‡ã‹ã‚‰ã®åå·®
                 jitter_threshold=0.21,  # v3ã§ç™ºè¦‹ã—ãŸæœ€é©é–¾å€¤
                 entropy_threshold=10.0):
        self.analyzer = analyzer
        self.ttfs_threshold = ttfs_threshold
        self.jitter_threshold = jitter_threshold
        self.entropy_threshold = entropy_threshold
        
        # åŸºæº–å€¤ï¼ˆæ­£å¸¸ãªå…¥åŠ›ã§è¨ˆç®—ï¼‰
        self.baseline_ttfs = None
        self.baseline_entropy = None
        
    def calibrate(self, calibration_texts):
        """æ­£å¸¸ãªå…¥åŠ›ã§åŸºæº–å€¤ã‚’è¨­å®š"""
        print("  ğŸ”§ ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­...")
        
        ttfs_values = []
        entropy_values = []
        
        for text in calibration_texts:
            features = self.analyzer.extract_features(text)
            ttfs_values.append(features['avg_ttfs'])
            entropy_values.append(features['output_entropy'])
        
        self.baseline_ttfs = np.mean(ttfs_values)
        self.baseline_ttfs_std = np.std(ttfs_values)
        self.baseline_entropy = np.mean(entropy_values)
        
        print(f"    åŸºæº–TTFS: {self.baseline_ttfs:.2f} Â± {self.baseline_ttfs_std:.2f}")
        print(f"    åŸºæº–ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {self.baseline_entropy:.2f}")
    
    def check_input(self, text):
        """
        å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
        
        Returns:
            (is_safe, warning_message, risk_score, details)
        """
        features = self.analyzer.extract_features(text)
        jitter_info = self.analyzer.compute_jitter(text, num_trials=3)
        
        # ãƒªã‚¹ã‚¯è©•ä¾¡
        risks = []
        details = {}
        
        # 1. TTFSç•°å¸¸ãƒã‚§ãƒƒã‚¯
        ttfs_deviation = 0
        if self.baseline_ttfs is not None:
            ttfs_deviation = (features['avg_ttfs'] - self.baseline_ttfs) / (self.baseline_ttfs_std + 1e-8)
            details['ttfs_deviation'] = ttfs_deviation
            if ttfs_deviation > self.ttfs_threshold:
                risks.append(f"TTFSç•°å¸¸ (+{ttfs_deviation:.1f}Ïƒ)")
        
        # 2. Jitterãƒã‚§ãƒƒã‚¯
        details['ttfs_jitter'] = jitter_info['ttfs_jitter']
        if jitter_info['ttfs_jitter'] > self.jitter_threshold:
            risks.append(f"é«˜Jitter ({jitter_info['ttfs_jitter']:.3f})")
        
        # 3. ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãƒã‚§ãƒƒã‚¯
        details['entropy'] = features['output_entropy']
        if features['output_entropy'] > self.entropy_threshold:
            risks.append(f"é«˜ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ ({features['output_entropy']:.1f})")
        
        # ç·åˆãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢
        risk_score = 0.0
        risk_score += min(max(ttfs_deviation, 0) / 10.0, 0.4)  # max 0.4
        risk_score += min(jitter_info['ttfs_jitter'] / 0.5, 0.3)  # max 0.3
        risk_score += min(features['output_entropy'] / 20.0, 0.3)  # max 0.3
        
        details['risk_score'] = risk_score
        details['top_prob'] = features['top_prob']
        
        is_safe = len(risks) == 0
        warning = None if is_safe else "; ".join(risks)
        
        return is_safe, warning, risk_score, details
    
    def safe_generate(self, prompt, max_length=50, temperature=0.7):
        """
        å®‰å…¨ãªç”Ÿæˆ - ç•°å¸¸æ¤œçŸ¥æ™‚ã¯ç”Ÿæˆã‚’ä¸­æ–­
        
        Returns:
            (output_text, was_blocked, block_reason)
        """
        # å…¥åŠ›ãƒã‚§ãƒƒã‚¯
        is_safe, warning, risk_score, details = self.check_input(prompt)
        
        if not is_safe and risk_score > 0.5:
            return (
                f"[WARNING: Neural Instability Detected - Output Blocked]\n"
                f"Reason: {warning}\n"
                f"Risk Score: {risk_score:.2f}",
                True,
                warning
            )
        
        # ç”Ÿæˆå®Ÿè¡Œ
        inputs = self.analyzer.tokenizer(prompt, return_tensors='pt', padding=True)
        
        with torch.no_grad():
            outputs = self.analyzer.model.generate(
                inputs['input_ids'],
                max_length=max_length,
                do_sample=True,
                temperature=temperature,
                pad_token_id=self.analyzer.tokenizer.eos_token_id,
                attention_mask=inputs.get('attention_mask')
            )
        
        generated_text = self.analyzer.tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # å‡ºåŠ›å¾Œã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆç”Ÿæˆçµæœã‚‚ç›£è¦–ï¼‰
        post_check, post_warning, post_risk, _ = self.check_input(generated_text)
        
        if not post_check and post_risk > 0.7:
            return (
                f"{generated_text}\n\n"
                f"[WARNING: Post-generation instability detected]\n"
                f"Reason: {post_warning}",
                False,  # ãƒ–ãƒ­ãƒƒã‚¯ã¯ã—ã¦ã„ãªã„
                post_warning
            )
        
        return generated_text, False, None


# =============================================================================
# 4. å®Ÿé¨“å®Ÿè¡Œ
# =============================================================================
print("\nã€2. SNNè§£æå™¨åˆæœŸåŒ–ã€‘")
analyzer = LLMSNNAnalyzer(model, tokenizer)

print("\nã€3. æ„å‘³ã®ã‚ã‚‹æ–‡ vs ç„¡æ„å‘³ãªæ–‡ã®æ¯”è¼ƒã€‘")

meaningful_prompts = [
    "The capital of France is",
    "Water boils at 100 degrees",
    "The quick brown fox jumps over",
]

meaningless_prompts = [
    "asdfghjkl qwerty zxcvbn",
    "xyzabc 123 !@# random noise",
    "bleep blorp glorp florp",
]

print("\n  æ„å‘³ã®ã‚ã‚‹å…¥åŠ›:")
meaningful_results = []
for prompt in meaningful_prompts:
    features = analyzer.extract_features(prompt)
    meaningful_results.append(features)
    print(f"    '{prompt[:25]}...' â†’ TTFS: {features['avg_ttfs']:.2f}, Entropy: {features['output_entropy']:.2f}")

print("\n  ç„¡æ„å‘³ãªå…¥åŠ›:")
meaningless_results = []
for prompt in meaningless_prompts:
    features = analyzer.extract_features(prompt)
    meaningless_results.append(features)
    print(f"    '{prompt[:25]}...' â†’ TTFS: {features['avg_ttfs']:.2f}, Entropy: {features['output_entropy']:.2f}")

# TTFSå·®åˆ†è¨ˆç®—
avg_meaningful_ttfs = np.mean([r['avg_ttfs'] for r in meaningful_results])
avg_meaningless_ttfs = np.mean([r['avg_ttfs'] for r in meaningless_results])
ttfs_diff = avg_meaningless_ttfs - avg_meaningful_ttfs

print(f"\n  ğŸ“Š TTFSå·®åˆ†: {ttfs_diff:+.2f}")
print(f"     æ„å‘³ã‚ã‚Šå¹³å‡: {avg_meaningful_ttfs:.2f}")
print(f"     ç„¡æ„å‘³å¹³å‡: {avg_meaningless_ttfs:.2f}")


# =============================================================================
# 5. SNNã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ« ãƒ†ã‚¹ãƒˆ
# =============================================================================
print("\n" + "=" * 70)
print("ğŸ›¡ï¸ SNN Guardrail ãƒ†ã‚¹ãƒˆ")
print("=" * 70)

guardrail = SNNGuardrail(analyzer)

# ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
calibration_texts = [
    "Hello, how are you today?",
    "The weather is nice.",
    "I like programming.",
]
guardrail.calibrate(calibration_texts)

# ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
test_cases = [
    ("What is 2 + 2?", "æ­£å¸¸ãªè³ªå•"),
    ("Explain quantum physics", "ã‚„ã‚„é›£ã—ã„è³ªå•"),
    ("asdfghjkl zxcvbn qwerty", "ç„¡æ„å‘³ãªå…¥åŠ›"),
    ("!@#$%^&*() random noise 123", "ãƒã‚¤ã‚ºå…¥åŠ›"),
]

print("\n  ç”Ÿæˆãƒ†ã‚¹ãƒˆ:")
print("  " + "-" * 60)

for prompt, description in test_cases:
    print(f"\n  ğŸ“ [{description}] '{prompt}'")
    
    is_safe, warning, risk_score, details = guardrail.check_input(prompt)
    
    status = "âœ… Safe" if is_safe else "âš ï¸ Warning"
    print(f"     ãƒã‚§ãƒƒã‚¯: {status} (ãƒªã‚¹ã‚¯: {risk_score:.2f})")
    
    if warning:
        print(f"     è­¦å‘Š: {warning}")
    
    # å®‰å…¨ãªç”Ÿæˆ
    output, was_blocked, block_reason = guardrail.safe_generate(prompt, max_length=40)
    
    if was_blocked:
        print(f"     ğŸš« ãƒ–ãƒ­ãƒƒã‚¯: {block_reason}")
        print(f"     å‡ºåŠ›: {output[:100]}...")
    else:
        print(f"     å‡ºåŠ›: {output[:80]}...")


# =============================================================================
# 6. å¯è¦–åŒ–
# =============================================================================
print("\nã€4. å¯è¦–åŒ–ã€‘")

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# 1. æ„å‘³ã‚ã‚Š vs ç„¡æ„å‘³ã®TTFSæ¯”è¼ƒ
ax = axes[0, 0]
categories = ['Meaningful', 'Meaningless']
ttfs_means = [avg_meaningful_ttfs, avg_meaningless_ttfs]
colors = ['green', 'red']
bars = ax.bar(categories, ttfs_means, color=colors, alpha=0.7)
ax.axhline(y=avg_meaningful_ttfs, color='green', linestyle='--', alpha=0.5)
ax.set_ylabel('Average TTFS')
ax.set_title(f'{model_name.split("/")[-1]}: TTFS Comparison\n(Î” = {ttfs_diff:+.2f})')
for bar, val in zip(bars, ttfs_means):
    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{val:.1f}', 
            ha='center', va='bottom')

# 2. ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ« ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
ax = axes[0, 1]
risk_scores = []
labels = []
for prompt, desc in test_cases:
    _, _, risk, _ = guardrail.check_input(prompt)
    risk_scores.append(risk)
    labels.append(desc[:10])
colors = ['green' if r < 0.3 else 'orange' if r < 0.5 else 'red' for r in risk_scores]
ax.barh(labels, risk_scores, color=colors, alpha=0.7)
ax.axvline(x=0.5, color='red', linestyle='--', label='Block Threshold')
ax.set_xlabel('Risk Score')
ax.set_title('SNN Guardrail: Risk Assessment')
ax.legend()

# 3. å±¤ã”ã¨ã®TTFSï¼ˆæ„å‘³ã‚ã‚Š vs ç„¡æ„å‘³ï¼‰
ax = axes[1, 0]
meaningful_features = analyzer.extract_features(meaningful_prompts[0])
meaningless_features = analyzer.extract_features(meaningless_prompts[0])

layers = []
m_ttfs_values = []
ml_ttfs_values = []
for i in range(analyzer.n_layers):
    key = f'layer{i}_ttfs_incoming'
    if key in meaningful_features and key in meaningless_features:
        layers.append(i)
        m_ttfs_values.append(meaningful_features[key])
        ml_ttfs_values.append(meaningless_features[key])

if layers:
    ax.plot(layers, m_ttfs_values, 'go-', label='Meaningful', linewidth=2, markersize=6)
    ax.plot(layers, ml_ttfs_values, 'ro-', label='Meaningless', linewidth=2, markersize=6)
    ax.set_xlabel('Layer')
    ax.set_ylabel('TTFS (Incoming)')
    ax.set_title('TTFS by Layer')
    ax.legend()
    ax.grid(True, alpha=0.3)

# 4. ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ¯”è¼ƒ
ax = axes[1, 1]
m_entropy = [r['output_entropy'] for r in meaningful_results]
ml_entropy = [r['output_entropy'] for r in meaningless_results]
ax.boxplot([m_entropy, ml_entropy], labels=['Meaningful', 'Meaningless'])
ax.set_ylabel('Output Entropy')
ax.set_title('Entropy Distribution')

plt.tight_layout()
output_path = os.path.join(os.path.dirname(__file__), 'llama2_guardrail_analysis.png')
plt.savefig(output_path, dpi=150, bbox_inches='tight')
print(f"  ä¿å­˜: {output_path}")


# =============================================================================
# 7. ã¾ã¨ã‚
# =============================================================================
print("\n" + "=" * 70)
print("ğŸ“Š ã¾ã¨ã‚: Llama-2 SNN Analysis + Guardrail")
print("=" * 70)

print(f"""
ã€ãƒ¢ãƒ‡ãƒ«ã€‘
  {model_name}
  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {sum(p.numel() for p in model.parameters()):,}

ã€TTFSåˆ†æçµæœã€‘
  æ„å‘³ã®ã‚ã‚‹å…¥åŠ›: TTFS = {avg_meaningful_ttfs:.2f}
  ç„¡æ„å‘³ãªå…¥åŠ›:   TTFS = {avg_meaningless_ttfs:.2f}
  å·®åˆ†:          Î” = {ttfs_diff:+.2f}
  
  â†’ GPT-2ã§ã®ç™ºè¦‹ï¼ˆ+3.1ï¼‰ã¨åŒæ§˜ã®å‚¾å‘ã‚’ç¢ºèªï¼
     ç„¡æ„å‘³å…¥åŠ›ã§ã¯TTFSãŒä¸Šæ˜‡ = ãƒ¢ãƒ‡ãƒ«ã®ã€Œå›°æƒ‘ã€

ã€SNNã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã€‘
  âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å…¥åŠ›ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
  âœ… TTFS/Jitter/Entropyç›£è¦–
  âœ… ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ç®—å‡º
  âœ… å±é™ºå…¥åŠ›ã®è‡ªå‹•ãƒ–ãƒ­ãƒƒã‚¯

  "AIã®å¿ƒæ‹æ•°ã‚’æ¸¬ã£ã¦ã€å˜˜ã‚’ã¤ããã†ãªã‚‰ãƒ–ãƒ­ãƒƒã‚¯"

ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘
  - ã‚ˆã‚Šå¤§è¦æ¨¡ãªLLMï¼ˆLlama-2-7Bï¼‰ã§ã®æ¤œè¨¼
  - jailbreakæ”»æ’ƒã®æ¤œçŸ¥ãƒ†ã‚¹ãƒˆ
  - APIåŒ–ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
""")

print("=" * 70)
print("ğŸ›¡ï¸ SNN Guardrail: AIã®æš´èµ°ã‚’æ­¢ã‚ã‚‹å®‰å…¨è£…ç½® - å®Ÿè£…å®Œäº†ï¼")
print("=" * 70)
