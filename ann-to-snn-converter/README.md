# Autonomous SNN Framework
# è‡ªå¾‹é€²åŒ–SNNãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ + AIè§£é‡ˆå¯èƒ½æ€§ãƒ„ãƒ¼ãƒ«

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![arXiv](https://img.shields.io/badge/arXiv-2026.XXXXX-b31b1b.svg)](https://arxiv.org/)

> ğŸ§  SNNã‚’ã€Œè¨ˆç®—ã®é¡•å¾®é¡ã€ã¨ã—ã¦ä½¿ç”¨ã—ã€ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹AIã‚’æ™‚é–“è»¸ã§è§£å‰–ã™ã‚‹

## ğŸ”¥ Main Features

### 1. ANN-to-SNNå¤‰æ›
- **Universal Threshold Formula**: $\theta = 2.0 \times \max(\text{activation})$
- **100%ç²¾åº¦ç¶­æŒ** (MLP, CNN, ResNet)
- **æµ·é¦¬ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ãƒ¼ãƒ‰ Hybrid Architecture**

### 2. AI Interpretabilityï¼ˆNEW! ğŸ†•ï¼‰
- **TTFS Analysis**: æ€è€ƒå„ªå…ˆé †ä½ã®å¯è¦–åŒ–
- **Neural Synchrony**: æ¦‚å¿µçµåˆã®æ¤œå‡º
- **Spike Stability**: AIåˆ¤æ–­ã®å®‰å®šæ€§è©•ä¾¡

### 3. ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œçŸ¥ï¼ˆNEW! ğŸ†•ï¼‰
- **AUC 0.75é”æˆ**ï¼ˆ5-fold CVï¼‰
- **è‡ªå‹•é–¾å€¤ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**ï¼ˆF1æœ€å¤§åŒ–ï¼‰
- **Ensembleå­¦ç¿’**ï¼ˆRF + GB + LR + SVMï¼‰

## ğŸ“Š Results

| å®Ÿé¨“ | çµæœ | è©³ç´° |
|------|------|------|
| ANN-SNNå¤‰æ› | 100%ç²¾åº¦ç¶­æŒ | Î±=2.0, Hybrid architecture |
| GPT-2 TTFS | +3.1å·® | ç„¡æ„å‘³å…¥åŠ›â†’é«˜TTFSï¼ˆè¿·ã„ï¼‰ |
| ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œçŸ¥ | AUC 0.75 | Ensemble + è‡ªå‹•é–¾å€¤ |
| ViT-Baseæ¤œè¨¼ | AUC 0.74 | 6.4M params, CIFAR-100 |

## ğŸ“ Repository Structure

```
autonomous-snn-framework/
â”œâ”€â”€ experiments/                    # å®Ÿé¨“ã‚³ãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ snn_interpretability.py       # TTFS/SynchronyåŸºæœ¬ç‰ˆ
â”‚   â”œâ”€â”€ snn_interpretability_advanced.py  # ã‚¯ãƒ©ã‚¹åˆ¥è§£æ
â”‚   â”œâ”€â”€ hallucination_detector.py     # v1: é–¾å€¤ãƒ™ãƒ¼ã‚¹
â”‚   â”œâ”€â”€ hallucination_detector_v2.py  # v2: å¤šç‰¹å¾´é‡
â”‚   â”œâ”€â”€ hallucination_detector_v3.py  # v3: Ensemble + è‡ªå‹•é–¾å€¤
â”‚   â”œâ”€â”€ transformer_snn_analysis.py   # MiniViTè§£æ
â”‚   â”œâ”€â”€ gpt2_snn_analysis.py          # HuggingFace GPT-2
â”‚   â””â”€â”€ large_scale_vit_validation.py # ViT-Baseæ¤œè¨¼
â”œâ”€â”€ api/                           # API
â”‚   â””â”€â”€ hallucination_api.py          # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œçŸ¥API
â”œâ”€â”€ core/                          # ã‚³ã‚¢ã‚¨ãƒ³ã‚¸ãƒ³
â”‚   â”œâ”€â”€ evolution_engine.py           # è‡ªå¾‹é€²åŒ–ã‚¨ãƒ³ã‚¸ãƒ³
â”‚   â”œâ”€â”€ motivation.py                 # å†…ç™ºçš„å‹•æ©Ÿãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”‚   â””â”€â”€ self_modifier.py              # è‡ªå·±æ”¹å¤‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”œâ”€â”€ applications/                  # å„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”‚   â”œâ”€â”€ crypto_snn.py                 # æš—å·ãƒ»åœ§ç¸®
â”‚   â”œâ”€â”€ language_snn.py               # è¨€èªãƒ¢ãƒ‡ãƒ«
â”‚   â””â”€â”€ vision_snn.py                 # ç”»åƒç”Ÿæˆ
â””â”€â”€ paper_arxiv_v8.tex             # è«–æ–‡ (v8)
```

## ğŸš€ Quick Start

### Requirements

```bash
pip install torch torchvision numpy matplotlib scikit-learn
pip install transformers  # GPT-2è§£æç”¨
pip install fastapi uvicorn  # APIç”¨ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
```

### åŸºæœ¬ä½¿ç”¨æ³•

```python
# 1. TTFSè§£æ
from experiments.snn_interpretability import SNNFeatureExtractor

extractor = SNNFeatureExtractor(timesteps=100)
features = extractor.extract(model, image)
print(f"Layer1 TTFS: {features['layer1_ttfs_mean']}")

# 2. ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œçŸ¥
from experiments.hallucination_detector_v3 import EnsembleHallucinationDetector

detector = EnsembleHallucinationDetector()
detector.fit(X_train, y_train)
risk_prob = detector.predict_proba(X_test)[:, 1]

# é–¾å€¤åˆ¤å®š
threshold = 0.210  # è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿
if risk_prob[0] >= threshold:
    print("âš ï¸ ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒªã‚¹ã‚¯é«˜")
else:
    print("âœ… ä¿¡é ¼ã§ãã‚‹äºˆæ¸¬")
```

### APIèµ·å‹•

```bash
cd api
uvicorn hallucination_api:app --reload --host 0.0.0.0 --port 8000
```

## ğŸ“ˆ Visualizations

### TTFS & Neural Synchrony Analysis
![TTFS Analysis](snn_interpretability_advanced.png)

### Hallucination Detector v3
![Hallucination Detector](hallucination_detector_v3.png)

### GPT-2 Attention TTFS
![GPT-2 Analysis](gpt2_snn_analysis.png)

### ViT-Base Large-Scale Validation
![ViT-Base](vit_base_cifar100_analysis.png)

## ğŸ”¬ Key Insights

### 1. TTFS = æ€è€ƒå„ªå…ˆé †ä½
é«˜ã„æ´»æ€§åŒ– â†’ æ—©ã„ã‚¹ãƒ‘ã‚¤ã‚¯ â†’ é«˜å„ªå…ˆåº¦

### 2. Synchrony = æ¦‚å¿µçµåˆ
åŒæœŸç™ºç«ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ç¾¤ = æ„å‘³ã®å¡Š

### 3. Jitter = åˆ¤æ–­ã®ä¸å®‰å®šæ€§
é«˜ã‚¸ãƒƒã‚¿ãƒ¼ + é«˜ç¢ºä¿¡åº¦ = ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒªã‚¹ã‚¯

### 4. GPT-2ã®ã€Œè¿·ã„ã€
ç„¡æ„å‘³å…¥åŠ› â†’ Attention TTFSãŒ+3.1å¢—åŠ  â†’ ãƒ¢ãƒ‡ãƒ«ãŒã€Œã©ã“ã‚’è¦‹ã¦ã„ã„ã‹ã‚ã‹ã‚‰ãªã„ã€

## ğŸ“ Citation

```bibtex
@article{funasaki2026snn_interpretability,
  title={Activation-Scaled ANN-to-SNN Conversion with SNN-Based AI Interpretability},
  author={Funasaki, Hiroto},
  journal={arXiv preprint},
  year={2026}
}
```

## ğŸ¤ Related Work

- [Von Neumann vs Brain-like Architecture](https://zenodo.org/records/...) - æƒ…å ±å®¹é‡æ¯”è¼ƒ
- [Hybrid Spiking Neural Networks](https://zenodo.org/records/...) - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰SNN
- [Hierarchical Memory SNN](https://zenodo.org/records/...) - éšå±¤çš„è¨˜æ†¶SNN

## ğŸ“œ License

MIT License - ã‚ãƒ¼ã‚‹ (cell_activation)

## ğŸ™ Acknowledgments

- HuggingFace Transformers for GPT-2 models
- PyTorch team for the deep learning framework
- Neuromorphic computing community for SNN research foundation
