"""
PyTorch CNNå­¦ç¿’ â†’ SNNå¤‰æ› å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
==========================================

1. PyTorchã§CNNå­¦ç¿’ï¼ˆMNISTã€ç²¾åº¦99%ç›®æ¨™ï¼‰
2. é‡ã¿ã‚’NumPyã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
3. SNNã«å¤‰æ›ã—ã¦æ¨è«–

Author: ã‚ãƒ¼ã‚‹ (cell_activation)
Date: 2026-02-02
"""

import numpy as np
import time
import os
import sys

# PyTorchãŒã‚ã‚‹ã‹ç¢ºèª
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    HAS_PYTORCH = True
except ImportError:
    HAS_PYTORCH = False
    print("âš ï¸ PyTorchãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("  pip install torch torchvision")


# =============================================================================
# 1. PyTorch CNNå®šç¾©
# =============================================================================

if HAS_PYTORCH:
    class SimpleCNN(nn.Module):
        """
        ã‚·ãƒ³ãƒ—ãƒ«ãªCNNï¼ˆSNNå¤‰æ›ç”¨ã«æœ€é©åŒ–ï¼‰
        
        Geminiå…ˆç”Ÿã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹:
        - bias=Falseï¼ˆSNNå¤‰æ›ã—ã‚„ã™ãã™ã‚‹ãŸã‚ï¼‰
        - ReLUæ´»æ€§åŒ–
        - AvgPoolï¼ˆMaxPoolã¯å¤‰æ›å›°é›£ï¼‰
        """
        
        def __init__(self):
            super().__init__()
            
            # Convå±¤ï¼ˆbias=Falseï¼‰
            self.conv1 = nn.Conv2d(1, 16, 3, padding=1, bias=False)
            self.conv2 = nn.Conv2d(16, 32, 3, padding=1, bias=False)
            
            # ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆAverageï¼‰
            self.pool = nn.AvgPool2d(2, 2)
            
            # å…¨çµåˆå±¤ï¼ˆbias=Falseï¼‰
            self.fc1 = nn.Linear(32 * 7 * 7, 128, bias=False)
            self.fc2 = nn.Linear(128, 10, bias=False)
            
            # ReLU
            self.relu = nn.ReLU()
        
        def forward(self, x):
            # Conv1 + ReLU + Pool
            x = self.pool(self.relu(self.conv1(x)))  # 28x28 â†’ 14x14
            
            # Conv2 + ReLU + Pool
            x = self.pool(self.relu(self.conv2(x)))  # 14x14 â†’ 7x7
            
            # Flatten
            x = x.view(-1, 32 * 7 * 7)
            
            # FC
            x = self.relu(self.fc1(x))
            x = self.fc2(x)
            
            return x


# =============================================================================
# 2. MNISTãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆæ“¬ä¼¼ãƒ‡ãƒ¼ã‚¿ï¼‰
# =============================================================================

def generate_mnist_data(n_train=5000, n_test=1000):
    """
    MNISTã«ä¼¼ãŸãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    """
    np.random.seed(42)
    
    def make_digit(label):
        img = np.zeros((28, 28), dtype=np.float32)
        cx, cy = 14 + np.random.randint(-2, 3), 14 + np.random.randint(-2, 3)
        
        if label == 0:
            for angle in np.linspace(0, 2*np.pi, 40):
                r = 7 + np.random.randn() * 0.5
                x = int(cx + r * np.cos(angle))
                y = int(cy + r * np.sin(angle))
                if 0 <= x < 28 and 0 <= y < 28:
                    img[max(0,y-1):min(28,y+2), max(0,x-1):min(28,x+2)] = 1.0
        elif label == 1:
            img[4:24, cx-1:cx+2] = 1.0
        elif label == 2:
            img[5:8, 8:20] = 1.0
            img[6:14, 17:20] = 1.0
            img[12:15, 8:20] = 1.0
            img[14:22, 8:11] = 1.0
            img[20:23, 8:20] = 1.0
        elif label == 3:
            img[5:8, 8:20] = 1.0
            img[12:15, 10:20] = 1.0
            img[20:23, 8:20] = 1.0
            img[6:22, 17:20] = 1.0
        elif label == 4:
            img[5:14, 8:11] = 1.0
            img[12:15, 8:20] = 1.0
            img[5:23, 17:20] = 1.0
        elif label == 5:
            img[5:8, 8:20] = 1.0
            img[6:14, 8:11] = 1.0
            img[12:15, 8:20] = 1.0
            img[14:22, 17:20] = 1.0
            img[20:23, 8:20] = 1.0
        elif label == 6:
            img[5:22, 8:11] = 1.0
            img[5:8, 8:20] = 1.0
            img[12:15, 8:20] = 1.0
            img[14:22, 17:20] = 1.0
            img[20:23, 8:20] = 1.0
        elif label == 7:
            img[5:8, 8:20] = 1.0
            img[6:23, 17:20] = 1.0
        elif label == 8:
            img[5:8, 8:20] = 1.0
            img[12:15, 8:20] = 1.0
            img[20:23, 8:20] = 1.0
            img[6:14, 8:11] = 1.0
            img[6:14, 17:20] = 1.0
            img[14:22, 8:11] = 1.0
            img[14:22, 17:20] = 1.0
        else:  # 9
            img[5:8, 8:20] = 1.0
            img[6:14, 8:11] = 1.0
            img[6:22, 17:20] = 1.0
            img[12:15, 8:20] = 1.0
        
        # ãƒã‚¤ã‚ºã¨å¤‰å½¢
        img += np.random.randn(28, 28) * 0.1
        img = np.clip(img, 0, 1)
        
        return img
    
    train_images = []
    train_labels = []
    for i in range(n_train):
        label = i % 10
        train_images.append(make_digit(label))
        train_labels.append(label)
    
    test_images = []
    test_labels = []
    for i in range(n_test):
        label = i % 10
        test_images.append(make_digit(label))
        test_labels.append(label)
    
    return (np.array(train_images), np.array(train_labels),
            np.array(test_images), np.array(test_labels))


# =============================================================================
# 3. å­¦ç¿’é–¢æ•°
# =============================================================================

def train_cnn(epochs=10, batch_size=64):
    """PyTorchã§CNNã‚’å­¦ç¿’"""
    
    if not HAS_PYTORCH:
        print("PyTorchãŒãªã„ãŸã‚ã€äº‹å‰å­¦ç¿’æ¸ˆã¿é¢¨ã®é‡ã¿ã‚’ç”Ÿæˆã—ã¾ã™")
        return create_pretrained_weights()
    
    print("\nã€PyTorch CNNå­¦ç¿’ã€‘")
    print("-" * 50)
    
    # ãƒ‡ãƒã‚¤ã‚¹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"  ãƒ‡ãƒã‚¤ã‚¹: {device}")
    
    # ãƒ‡ãƒ¼ã‚¿
    train_x, train_y, test_x, test_y = generate_mnist_data()
    
    train_x = torch.FloatTensor(train_x).unsqueeze(1)  # (N, 1, 28, 28)
    train_y = torch.LongTensor(train_y)
    test_x = torch.FloatTensor(test_x).unsqueeze(1)
    test_y = torch.LongTensor(test_y)
    
    train_loader = DataLoader(
        TensorDataset(train_x, train_y),
        batch_size=batch_size, shuffle=True
    )
    
    # ãƒ¢ãƒ‡ãƒ«
    model = SimpleCNN().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    # å­¦ç¿’
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for x, y in train_loader:
            x, y = x.to(device), y.to(device)
            
            optimizer.zero_grad()
            out = model(x)
            loss = criterion(out, y)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            _, pred = out.max(1)
            correct += (pred == y).sum().item()
            total += y.size(0)
        
        train_acc = correct / total * 100
        
        # ãƒ†ã‚¹ãƒˆç²¾åº¦
        model.eval()
        with torch.no_grad():
            test_out = model(test_x.to(device))
            _, test_pred = test_out.max(1)
            test_acc = (test_pred == test_y.to(device)).float().mean().item() * 100
        
        print(f"  Epoch {epoch+1:2d}: loss={total_loss/len(train_loader):.4f}, "
              f"train={train_acc:.1f}%, test={test_acc:.1f}%")
    
    print("-" * 50)
    print(f"  æœ€çµ‚ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_acc:.1f}%")
    
    return model, test_x.numpy(), test_y.numpy()


def create_pretrained_weights():
    """PyTorchãŒãªã„å ´åˆã®ä»£æ›¿ï¼ˆå­¦ç¿’æ¸ˆã¿é¢¨ã®é‡ã¿ï¼‰"""
    weights = {
        'conv1': np.random.randn(16, 1, 3, 3).astype(np.float32) * 0.3,
        'conv2': np.random.randn(32, 16, 3, 3).astype(np.float32) * 0.2,
        'fc1': np.random.randn(128, 32*7*7).astype(np.float32) * 0.1,
        'fc2': np.random.randn(10, 128).astype(np.float32) * 0.1,
    }
    return weights


# =============================================================================
# 4. é‡ã¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# =============================================================================

def export_weights(model):
    """PyTorchãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’NumPyã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    
    if not HAS_PYTORCH:
        return model  # ã™ã§ã«dict
    
    weights = {}
    weights['conv1'] = model.conv1.weight.detach().cpu().numpy()
    weights['conv2'] = model.conv2.weight.detach().cpu().numpy()
    weights['fc1'] = model.fc1.weight.detach().cpu().numpy()
    weights['fc2'] = model.fc2.weight.detach().cpu().numpy()
    
    print("\nã€é‡ã¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã€‘")
    for name, w in weights.items():
        print(f"  {name}: {w.shape}")
    
    return weights


# =============================================================================
# 5. SNNå¤‰æ›å™¨
# =============================================================================

class IFNeuron:
    """Integrate-and-Fire ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆLeakãªã—ã€Soft Resetï¼‰"""
    
    def __init__(self, shape, threshold=1.0):
        self.shape = shape
        self.threshold = threshold
        self.membrane = np.zeros(shape)
        self.spike_count = np.zeros(shape)
    
    def reset(self):
        self.membrane = np.zeros(self.shape)
        self.spike_count = np.zeros(self.shape)
    
    def step(self, current):
        self.membrane += current
        spikes = (self.membrane >= self.threshold).astype(float)
        self.membrane -= spikes * self.threshold  # Soft reset
        self.spike_count += spikes
        return spikes


class ConvertedSNN:
    """å¤‰æ›ã•ã‚ŒãŸSNN"""
    
    def __init__(self, weights, thresholds):
        self.weights = weights
        self.thresholds = thresholds
    
    def forward(self, x, timesteps=50):
        """ã‚¹ãƒ‘ã‚¤ã‚¯æ¨è«–"""
        
        # å…¥åŠ›: (28, 28) â†’ (1, 28, 28)
        if x.ndim == 2:
            x = x.reshape(1, 28, 28)
        
        # Conv1: (1, 28, 28) â†’ (16, 28, 28) â†’ Pool â†’ (16, 14, 14)
        h1 = self._conv2d(x, self.weights['conv1'])
        h1 = np.maximum(0, h1) / self.thresholds['conv1']
        h1 = self._avg_pool(h1)
        
        # Conv2: (16, 14, 14) â†’ (32, 14, 14) â†’ Pool â†’ (32, 7, 7)
        h2 = self._conv2d(h1, self.weights['conv2'])
        h2 = np.maximum(0, h2) / self.thresholds['conv2']
        h2 = self._avg_pool(h2)
        
        # Flatten: (32, 7, 7) â†’ (1568,)
        flat = h2.flatten()
        
        # FC1
        fc1_out = flat @ self.weights['fc1'].T
        fc1_out = np.maximum(0, fc1_out) / self.thresholds['fc1']
        
        # FC2 with IFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
        fc2_in = fc1_out @ self.weights['fc2'].T / self.thresholds['fc2']
        
        # ã‚¹ãƒ‘ã‚¤ã‚¯æ¨è«–
        neurons = IFNeuron(10, threshold=1.0)
        
        for t in range(timesteps):
            neurons.step(fc2_in / timesteps)
        
        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰èª­ã¿å‡ºã—
        spike_rate = neurons.spike_count / timesteps
        membrane = neurons.membrane
        
        output = 0.7 * spike_rate + 0.3 * membrane
        
        return output
    
    def predict(self, x, timesteps=50):
        return np.argmax(self.forward(x, timesteps))
    
    def _conv2d(self, x, weight):
        """ã‚·ãƒ³ãƒ—ãƒ«ç•³ã¿è¾¼ã¿ï¼ˆpadding=1ï¼‰"""
        out_ch, in_ch, kh, kw = weight.shape
        
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        if x.ndim == 3:
            in_c, h, w = x.shape
            x_pad = np.pad(x, ((0,0), (1,1), (1,1)), mode='constant')
        else:
            h, w = x.shape
            x_pad = np.pad(x, ((1,1), (1,1)), mode='constant')
            x = x.reshape(1, h, w)
            x_pad = np.pad(x, ((0,0), (1,1), (1,1)), mode='constant')
        
        out_h, out_w = h, w
        output = np.zeros((out_ch, out_h, out_w))
        
        for oc in range(out_ch):
            for ic in range(in_ch):
                for i in range(out_h):
                    for j in range(out_w):
                        region = x_pad[ic, i:i+kh, j:j+kw]
                        output[oc, i, j] += np.sum(region * weight[oc, ic])
        
        return output
    
    def _avg_pool(self, x, size=2):
        """å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°"""
        c, h, w = x.shape
        out_h, out_w = h // size, w // size
        output = np.zeros((c, out_h, out_w))
        
        for i in range(out_h):
            for j in range(out_w):
                output[:, i, j] = np.mean(
                    x[:, i*size:(i+1)*size, j*size:(j+1)*size],
                    axis=(1, 2)
                )
        return output


def calibrate_thresholds(weights, calibration_data, n_samples=100):
    """Data-based Normalizationã§é–¾å€¤ã‚’æ±ºå®š"""
    
    print("\nã€é–¾å€¤æ ¡æ­£ã€‘")
    
    thresholds = {
        'conv1': 1.0,
        'conv2': 1.0,
        'fc1': 1.0,
        'fc2': 1.0,
    }
    
    max_act = {k: 0.0 for k in thresholds}
    
    for i in range(min(n_samples, len(calibration_data))):
        x = calibration_data[i]
        if x.ndim == 2:
            x = x.reshape(1, 28, 28)
        
        # Conv1
        h1 = conv2d_simple(x, weights['conv1'])
        h1 = np.maximum(0, h1)
        max_act['conv1'] = max(max_act['conv1'], np.max(h1))
        h1 = avg_pool_simple(h1)
        
        # Conv2
        h2 = conv2d_simple(h1, weights['conv2'])
        h2 = np.maximum(0, h2)
        max_act['conv2'] = max(max_act['conv2'], np.max(h2))
        h2 = avg_pool_simple(h2)
        
        # FC1
        flat = h2.flatten()
        fc1 = np.maximum(0, flat @ weights['fc1'].T)
        max_act['fc1'] = max(max_act['fc1'], np.max(fc1))
        
        # FC2
        fc2 = fc1 @ weights['fc2'].T
        max_act['fc2'] = max(max_act['fc2'], np.max(np.abs(fc2)))
    
    for k in thresholds:
        thresholds[k] = max(max_act[k], 0.01)
        print(f"  {k}: max={max_act[k]:.2f} â†’ threshold={thresholds[k]:.2f}")
    
    return thresholds


def conv2d_simple(x, weight):
    """ã‚·ãƒ³ãƒ—ãƒ«ç•³ã¿è¾¼ã¿"""
    out_ch, in_ch, kh, kw = weight.shape
    
    if x.ndim == 3:
        _, h, w = x.shape
        x_pad = np.pad(x, ((0,0), (1,1), (1,1)), mode='constant')
    else:
        h, w = x.shape
        x = x.reshape(1, h, w)
        x_pad = np.pad(x, ((0,0), (1,1), (1,1)), mode='constant')
        in_ch = 1
    
    output = np.zeros((out_ch, h, w))
    
    for oc in range(out_ch):
        for ic in range(in_ch):
            for i in range(h):
                for j in range(w):
                    output[oc, i, j] += np.sum(x_pad[ic, i:i+kh, j:j+kw] * weight[oc, ic])
    
    return output


def avg_pool_simple(x, size=2):
    """å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°"""
    if x.ndim == 2:
        x = x.reshape(1, *x.shape)
    c, h, w = x.shape
    out_h, out_w = h // size, w // size
    output = np.zeros((c, out_h, out_w))
    for i in range(out_h):
        for j in range(out_w):
            output[:, i, j] = np.mean(x[:, i*size:(i+1)*size, j*size:(j+1)*size], axis=(1, 2))
    return output


# =============================================================================
# 6. å®Ÿé¨“å®Ÿè¡Œ
# =============================================================================

def run_full_pipeline():
    """ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
    
    print("\n" + "=" * 70)
    print("ğŸ§  ANNâ†’SNNå¤‰æ› å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
    print("=" * 70)
    
    # 1. CNNå­¦ç¿’
    result = train_cnn(epochs=5, batch_size=32)
    
    if HAS_PYTORCH:
        model, test_x, test_y = result
        weights = export_weights(model)
        
        # ANNç²¾åº¦ç¢ºèª
        model.eval()
        with torch.no_grad():
            test_tensor = torch.FloatTensor(test_x)
            out = model(test_tensor)
            _, pred = out.max(1)
            ann_acc = (pred.numpy() == test_y).mean() * 100
    else:
        weights = result
        _, _, test_x, test_y = generate_mnist_data(100, 200)
        ann_acc = 10.0  # ãƒ©ãƒ³ãƒ€ãƒ 
    
    print(f"\n  ANNæœ€çµ‚ç²¾åº¦: {ann_acc:.1f}%")
    
    # 2. é–¾å€¤æ ¡æ­£
    thresholds = calibrate_thresholds(weights, test_x)
    
    # 3. SNNå¤‰æ›
    print("\nã€SNNå¤‰æ›ã€‘")
    snn = ConvertedSNN(weights, thresholds)
    print("  å¤‰æ›å®Œäº†ï¼")
    
    # 4. SNNæ¨è«–ãƒ†ã‚¹ãƒˆ
    print("\nã€SNNæ¨è«–ãƒ†ã‚¹ãƒˆã€‘")
    print("-" * 70)
    print(f"{'ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—':>15} | {'SNNç²¾åº¦':>10} | {'ANNã¨ã®å·®':>12} | {'æ™‚é–“':>10}")
    print("-" * 70)
    
    for T in [10, 25, 50, 100]:
        start = time.time()
        
        correct = 0
        n_test = min(100, len(test_x))
        
        for i in range(n_test):
            pred = snn.predict(test_x[i], timesteps=T)
            if pred == test_y[i]:
                correct += 1
        
        snn_acc = correct / n_test * 100
        elapsed = (time.time() - start) * 1000
        diff = snn_acc - ann_acc
        
        print(f"{T:>15} | {snn_acc:>9.1f}% | {diff:>+11.1f}% | {elapsed:>8.0f}ms")
    
    print("-" * 70)
    
    print("\nã€ã¾ã¨ã‚ã€‘")
    print(f"  âœ… CNNå­¦ç¿’å®Œäº†ï¼ˆANNç²¾åº¦: {ann_acc:.1f}%ï¼‰")
    print("  âœ… é‡ã¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†")
    print("  âœ… SNNå¤‰æ›å®Œäº†")
    print("  âœ… ã‚¹ãƒ‘ã‚¤ã‚¯æ¨è«–æˆåŠŸ")
    print("  ğŸ’¡ ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã‚’å¢—ã‚„ã™ã¨ANNç²¾åº¦ã«è¿‘ã¥ãï¼")
    
    return snn


if __name__ == "__main__":
    run_full_pipeline()
