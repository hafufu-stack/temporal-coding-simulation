"""
æµ·é¦¬ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ãƒ»ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰SNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
================================================

è„³ã®æµ·é¦¬ï¼ˆDG-CA3-CA1ï¼‰ã®å½¹å‰²åˆ†æ‹…ã«ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ï¼š
- DGï¼ˆå…¥åŠ›ï¼‰: ANNç‰¹å¾´æŠ½å‡ºï¼ˆå¼·ã„å…¥åŠ›ã‚’ä½œã‚‹ï¼‰
- CA3ï¼ˆä¸­é–“ï¼‰: å†å¸°SNNï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ä¿æŒï¼‰
- CA1ï¼ˆå‡ºåŠ›ï¼‰: SNNå‡ºåŠ›ï¼ˆÎ±=2.0èª­ã¿å‡ºã—ï¼‰

Author: ã‚ãƒ¼ã‚‹ (Cell Activation)
Date: 2026-02-03
"""

import os
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import time

print("=" * 70)
print("ğŸ§  æµ·é¦¬ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ãƒ»ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰SNN")
print("=" * 70)

# ============================================================
# 1. ãƒ‡ãƒ¼ã‚¿æº–å‚™
# ============================================================
print("\nã€1. CIFAR-10ãƒ‡ãƒ¼ã‚¿æº–å‚™ã€‘")

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

train_subset = torch.utils.data.Subset(trainset, range(10000))
test_subset = torch.utils.data.Subset(testset, range(1000))

trainloader = DataLoader(train_subset, batch_size=128, shuffle=True, num_workers=0)
testloader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=0)

print(f"  è¨“ç·´: {len(train_subset)}, ãƒ†ã‚¹ãƒˆ: {len(test_subset)}")

# ============================================================
# 2. æµ·é¦¬ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ãƒ»ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«
# ============================================================
print("\nã€2. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã€‘")

class HippocampalHybridNet(nn.Module):
    """
    æµ·é¦¬ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    
    DG (Dentate Gyrus) ç›¸å½“: 
      - Convç‰¹å¾´æŠ½å‡ºï¼ˆANNï¼‰
      - ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é›¢ã€å¼·ã„å…¥åŠ›ç”Ÿæˆ
    
    CA3 ç›¸å½“:
      - å†å¸°çµåˆå±¤ï¼ˆSNNé¢¨ã®å‡¦ç†ï¼‰
      - ãƒ‘ã‚¿ãƒ¼ãƒ³ä¿æŒãƒ»é€£æƒ³
    
    CA1 ç›¸å½“:
      - å‡ºåŠ›å±¤ï¼ˆSNNã€Î±=2.0ï¼‰
      - èª­ã¿å‡ºã—
    """
    def __init__(self):
        super().__init__()
        
        # === DGï¼ˆæ­¯çŠ¶å›ï¼‰: å…¥åŠ›å‡¦ç†ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é›¢ ===
        # å¼·åŠ›ãªç‰¹å¾´æŠ½å‡ºï¼ˆãƒ‡ãƒˆãƒãƒ¼ã‚¿ãƒ¼çš„ï¼‰
        self.dg_conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)
        self.dg_pool = nn.AvgPool2d(2)  # 32â†’16
        self.dg_conv2 = nn.Conv2d(64, 128, 3, 1, 1, bias=False)
        self.dg_pool2 = nn.AvgPool2d(2)  # 16â†’8
        
        # === CA3: å†å¸°çµåˆå±¤ ===
        # è‡ªå·±å†å¸°çš„ãªå‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        self.ca3_hidden = nn.Linear(128 * 8 * 8, 256, bias=False)
        self.ca3_recurrent = nn.Linear(256, 256, bias=False)  # å†å¸°çµåˆ
        
        # === CA1: å‡ºåŠ›å±¤ ===
        self.ca1_output = nn.Linear(256, 10, bias=False)
    
    def forward(self, x):
        # DGå‡¦ç†
        x = torch.relu(self.dg_conv1(x))
        x = self.dg_pool(x)
        x = torch.relu(self.dg_conv2(x))
        x = self.dg_pool2(x)
        x = x.view(x.size(0), -1)
        
        # CA3å‡¦ç†ï¼ˆå†å¸°ãªã—ã€å­¦ç¿’æ™‚ï¼‰
        ca3 = torch.relu(self.ca3_hidden(x))
        
        # CA1å‡ºåŠ›
        out = self.ca1_output(ca3)
        return out
    
    def forward_with_recurrent(self, x, recurrent_steps=3):
        """å†å¸°çµåˆã‚’ä½¿ã£ãŸæ¨è«–"""
        # DGå‡¦ç†
        x = torch.relu(self.dg_conv1(x))
        x = self.dg_pool(x)
        x = torch.relu(self.dg_conv2(x))
        x = self.dg_pool2(x)
        x = x.view(x.size(0), -1)
        
        # CA3å‡¦ç†ï¼ˆå†å¸°ã‚ã‚Šï¼‰
        ca3 = torch.relu(self.ca3_hidden(x))
        
        # å†å¸°çµåˆã‚’æ•°ã‚¹ãƒ†ãƒƒãƒ—å›ã™ï¼ˆCA3ã®è‡ªå·±æ´»æ€§åŒ–ï¼‰
        for _ in range(recurrent_steps):
            ca3_recur = torch.relu(self.ca3_recurrent(ca3))
            ca3 = 0.5 * ca3 + 0.5 * ca3_recur  # å…ƒã®æ´»æ€§åŒ–ã¨æ··åˆ
        
        # CA1å‡ºåŠ›
        out = self.ca1_output(ca3)
        return out


model = HippocampalHybridNet()
print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
print("""
  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ DGï¼ˆæ­¯çŠ¶å›ï¼‰: Conv64 â†’ Conv128      â”‚ â† ANNç‰¹å¾´æŠ½å‡º
  â”‚   â†“                                 â”‚
  â”‚ CA3: FC256 + å†å¸°çµåˆ               â”‚ â† SNNé¢¨ãƒ‘ã‚¿ãƒ¼ãƒ³ä¿æŒ
  â”‚   â†“                                 â”‚
  â”‚ CA1: FC10ï¼ˆÎ±=2.0 SNNå‡ºåŠ›ï¼‰          â”‚ â† SNNèª­ã¿å‡ºã—
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# ============================================================
# 3. å­¦ç¿’
# ============================================================
print("\nã€3. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã€‘")

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

for epoch in range(10):
    model.train()
    for inputs, labels in trainloader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    
    if (epoch + 1) % 2 == 0:
        model.eval()
        correct = total = 0
        with torch.no_grad():
            for inputs, labels in testloader:
                outputs = model(inputs)
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()
        print(f"  Epoch {epoch+1}: {100.*correct/total:.1f}%")

# ANNç²¾åº¦
model.eval()
correct = total = 0
with torch.no_grad():
    for inputs, labels in testloader:
        outputs = model(inputs)
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
ann_acc = 100. * correct / total
print(f"\n  ã€ANNç²¾åº¦ï¼ˆé€šå¸¸æ¨è«–ï¼‰ã€‘{ann_acc:.1f}%")

# å†å¸°çµåˆã‚’ä½¿ã£ãŸæ¨è«–
correct_recur = total = 0
with torch.no_grad():
    for inputs, labels in testloader:
        outputs = model.forward_with_recurrent(inputs, recurrent_steps=3)
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct_recur += predicted.eq(labels).sum().item()
recur_acc = 100. * correct_recur / total
print(f"  ã€ANNç²¾åº¦ï¼ˆCA3å†å¸°3stepï¼‰ã€‘{recur_acc:.1f}%")

# ============================================================
# 4. CA1å±¤ã®SNNåŒ–ãƒ†ã‚¹ãƒˆ
# ============================================================
print("\nã€4. CA1å±¤ã®SNNåŒ–ï¼ˆÎ±=2.0ï¼‰ã€‘")

# CA3å‡ºåŠ›ã®æœ€å¤§å€¤ã‚’è¨ˆæ¸¬
ca3_max = 0
with torch.no_grad():
    for inputs, _ in trainloader:
        x = torch.relu(model.dg_conv1(inputs))
        x = model.dg_pool(x)
        x = torch.relu(model.dg_conv2(x))
        x = model.dg_pool2(x)
        x = x.view(x.size(0), -1)
        ca3 = torch.relu(model.ca3_hidden(x))
        ca3_max = max(ca3_max, ca3.abs().max().item())

print(f"  CA3æœ€å¤§æ´»æ€§åŒ–: {ca3_max:.2f}")

# CA1å±¤ã‚’SNNåŒ–
def snn_ca1_inference(ca3_activation, alpha, T):
    """CA1å±¤ã®ã¿ã‚’SNNåŒ–ã—ã¦æ¨è«–"""
    batch_size = ca3_activation.shape[0]
    w_ca1 = model.ca1_output.weight.detach().numpy()
    
    threshold = alpha * ca3_max
    
    # IFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
    membrane = np.zeros((batch_size, 10))
    spike_count = np.zeros((batch_size, 10))
    
    # å…¥åŠ›ã‚’æ™‚é–“åˆ†æ•£
    current = ca3_activation.numpy() @ w_ca1.T
    current_per_step = current / T
    
    for t in range(T):
        membrane += current_per_step
        spikes = (membrane >= threshold).astype(float)
        membrane -= spikes * threshold
        spike_count += spikes
    
    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰èª­ã¿å‡ºã—
    output = 0.7 * (spike_count / T) + 0.3 * (membrane / threshold)
    return np.argmax(output, axis=1)


print("\n  æµ·é¦¬SNNç²¾åº¦ãƒ†ã‚¹ãƒˆ:")
print("-" * 70)
print(f"  {'æ–¹å¼':^25} | {'Î±':>6} | {'ç²¾åº¦':>8} | {'ANNå·®':>8}")
print("-" * 70)

T = 50

for alpha in [1.0, 1.5, 2.0, 2.5, 3.0]:
    correct = 0
    total = 0
    
    with torch.no_grad():
        for inputs, labels in testloader:
            # DG + CA3å‡¦ç†ï¼ˆANNï¼‰
            x = torch.relu(model.dg_conv1(inputs))
            x = model.dg_pool(x)
            x = torch.relu(model.dg_conv2(x))
            x = model.dg_pool2(x)
            x = x.view(x.size(0), -1)
            ca3 = torch.relu(model.ca3_hidden(x))
            
            # CA1ã‚’SNNåŒ–
            preds = snn_ca1_inference(ca3, alpha, T)
            correct += (preds == labels.numpy()).sum()
            total += len(labels)
    
    snn_acc = 100. * correct / total
    diff = snn_acc - ann_acc
    marker = " âœ…" if abs(diff) < 3 else ""
    print(f"  {'DG(ANN)+CA3(ANN)+CA1(SNN)':<25} | {alpha:>6.1f} | {snn_acc:>7.1f}% | {diff:>+7.1f}%{marker}")

# CA3ã«å†å¸°ã‚’è¿½åŠ ã—ãŸå ´åˆ
print()
for alpha in [2.0]:
    for recur_steps in [0, 1, 3, 5]:
        correct = 0
        total = 0
        
        with torch.no_grad():
            for inputs, labels in testloader:
                # DGå‡¦ç†
                x = torch.relu(model.dg_conv1(inputs))
                x = model.dg_pool(x)
                x = torch.relu(model.dg_conv2(x))
                x = model.dg_pool2(x)
                x = x.view(x.size(0), -1)
                
                # CA3å‡¦ç†ï¼ˆå†å¸°ä»˜ãï¼‰
                ca3 = torch.relu(model.ca3_hidden(x))
                for _ in range(recur_steps):
                    ca3_recur = torch.relu(model.ca3_recurrent(ca3))
                    ca3 = 0.5 * ca3 + 0.5 * ca3_recur
                
                # CA1ã‚’SNNåŒ–
                preds = snn_ca1_inference(ca3, alpha, T)
                correct += (preds == labels.numpy()).sum()
                total += len(labels)
        
        snn_acc = 100. * correct / total
        diff = snn_acc - ann_acc
        method = f"DG+CA3(å†å¸°{recur_steps})+CA1(SNN)"
        marker = " âœ…" if abs(diff) < 3 else ""
        print(f"  {method:<25} | {alpha:>6.1f} | {snn_acc:>7.1f}% | {diff:>+7.1f}%{marker}")

print("-" * 70)

# ============================================================
# 5. çµæœ
# ============================================================
print("\n" + "=" * 70)
print("ğŸ“Š æµ·é¦¬ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ãƒ»ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰SNN çµæœ")
print("=" * 70)
print(f"""
  ã€ANNç²¾åº¦ã€‘{ann_acc:.1f}%
  
  ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€‘
    DGï¼ˆæ­¯çŠ¶å›ï¼‰: Convå±¤ï¼ˆANNï¼‰ - ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é›¢
    CA3: FCå±¤ + å†å¸°çµåˆï¼ˆANN/SNNæ··åˆï¼‰ - ãƒ‘ã‚¿ãƒ¼ãƒ³ä¿æŒ
    CA1: å‡ºåŠ›å±¤ï¼ˆSNNã€Î±=2.0ï¼‰ - èª­ã¿å‡ºã—
  
  ã€ä»®èª¬ã€‘
    - è„³ã®å„éƒ¨ä½ã¯ç•°ãªã‚‹æ€§è³ªã‚’æŒã¤
    - ANNï¼ˆé€£ç¶šå€¤å‡¦ç†ï¼‰ã¨SNNï¼ˆã‚¹ãƒ‘ã‚¤ã‚¯å‡¦ç†ï¼‰ã‚’
      éƒ¨ä½ã”ã¨ã«ä½¿ã„åˆ†ã‘ã‚‹ã“ã¨ã§ç²¾åº¦ç¶­æŒã§ãã‚‹ï¼Ÿ
""")
