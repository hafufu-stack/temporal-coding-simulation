"""
GPT4Allå®Ÿãƒ¢ãƒ‡ãƒ«è’¸ç•™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
=============================

å®Ÿéš›ã®GPT4Allãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è’¸ç•™

Author: ã‚ãƒ¼ã‚‹ (cell_activation)
Date: 2026-01-31
"""

import os
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from gpt4all import GPT4All
from applications.llm_distillation import DecimalLLM, LLMDistiller


def main():
    print("\n" + "=" * 70)
    print("ğŸ¤– GPT4All å®Ÿãƒ¢ãƒ‡ãƒ«è’¸ç•™")
    print("=" * 70)
    
    # è»½é‡ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼ˆç´„2GBãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰
    model_name = "orca-mini-3b-gguf2-q4_0.gguf"
    
    print(f"\nã€ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€‘")
    print(f"  ãƒ¢ãƒ‡ãƒ«: {model_name}")
    print(f"  â€»åˆå›ã¯2-3GBã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒç™ºç”Ÿã—ã¾ã™...")
    
    try:
        model = GPT4All(model_name)
        print("  âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")
    except Exception as e:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    print("\nã€GPT4Allå¿œç­”ãƒ†ã‚¹ãƒˆã€‘")
    test_prompts = [
        "Hello, how are you?",
        "What is 2+2?",
        "What is artificial intelligence?",
    ]
    
    responses = []
    for prompt in test_prompts:
        print(f"\n  Q: {prompt}")
        response = model.generate(
            prompt,
            max_tokens=50,
            temp=0.7,
            top_p=0.9
        )
        print(f"  A: {response[:100]}...")
        responses.append((prompt, response))
    
    # 10é€²æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¸è’¸ç•™
    print("\n" + "=" * 50)
    print("ğŸ”¬ 10é€²æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¸è’¸ç•™")
    print("=" * 50)
    
    # ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«
    student = DecimalLLM(hidden_size=32, n_layers=4, context_length=64)
    distiller = LLMDistiller(student)
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    print("\nã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä½œæˆã€‘")
    
    # GPT4Allã‹ã‚‰å¿œç­”ã‚’åé›†
    training_prompts = [
        "Hello",
        "Hi there",
        "What is AI?",
        "How are you?",
        "Tell me a joke",
        "What is the capital of Japan?",
        "What is 1+1?",
        "What is programming?",
    ]
    
    for prompt in training_prompts:
        response = model.generate(prompt, max_tokens=30, temp=0.5)
        distiller.add_training_pair(prompt, response)
        print(f"  '{prompt}' â†’ '{response[:40]}...'")
    
    # è’¸ç•™
    print("\nã€è’¸ç•™å®Ÿè¡Œã€‘")
    distiller.distill(epochs=20)
    
    # è©•ä¾¡
    print("\nã€è©•ä¾¡ã€‘")
    results = distiller.evaluate()
    print(f"  ç²¾åº¦: {results['accuracy']:.2%}")
    
    # ã‚µã‚¤ã‚ºæ¯”è¼ƒ
    print("\n" + "=" * 50)
    print("ğŸ“Š ã‚µã‚¤ã‚ºæ¯”è¼ƒ")
    print("=" * 50)
    
    student_stats = student.get_stats()
    print(f"""
| ãƒ¢ãƒ‡ãƒ« | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ã‚µã‚¤ã‚º |
|--------|-----------|--------|
| GPT4All Orca 3B | ~3,000,000,000 | ~2GB |
| 10é€²æ•°LLM | {student_stats['total_neurons']} | ~{student_stats['total_neurons'] * 4 // 1000}KB |

åœ§ç¸®ç‡: {3_000_000_000 // student_stats['total_neurons']:,}å€!
""")
    
    print("\n" + "=" * 70)
    print("âœ… è’¸ç•™å®Œäº†ï¼")
    print("=" * 70)
    
    return student


if __name__ == "__main__":
    main()
