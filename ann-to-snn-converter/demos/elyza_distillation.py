"""
ELYZAæ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«è’¸ç•™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
================================

ELYZA-japanese-Llama-2-7bã‚’ä½¿ç”¨ã—ã¦
10é€²æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¸æ—¥æœ¬èªèƒ½åŠ›ã‚’è’¸ç•™

Author: ã‚ãƒ¼ã‚‹ (cell_activation)
Date: 2026-01-31
"""

import os
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from gpt4all import GPT4All
from applications.llm_distillation import DecimalLLM, LLMDistiller


def main():
    print("\n" + "=" * 70)
    print("ğŸ‡¯ğŸ‡µ ELYZAæ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«è’¸ç•™")
    print("=" * 70)
    
    # ELYZAæ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ï¼ˆç´„4GBãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰
    # GPT4Allã§åˆ©ç”¨å¯èƒ½ãªELYZAãƒ¢ãƒ‡ãƒ«
    model_name = "elyza-japanese-llama-2-7b-fast-instruct.Q4_K_M.gguf"
    
    print(f"\nã€ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€‘")
    print(f"  ãƒ¢ãƒ‡ãƒ«: {model_name}")
    print(f"  ã‚µã‚¤ã‚º: ç´„4GB")
    print(f"  â€»åˆå›ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«æ•°åˆ†ã‹ã‹ã‚Šã¾ã™...")
    
    try:
        # GPT4Allã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        # allow_download=Trueã§è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        model = GPT4All(model_name, allow_download=True)
        print("  âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")
    except Exception as e:
        print(f"  ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä»£æ›¿ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã—ã¾ã™...")
        # ä»£æ›¿: è»½é‡ãªæ—¥æœ¬èªå¯¾å¿œãƒ¢ãƒ‡ãƒ«
        try:
            model = GPT4All("mistral-7b-instruct-v0.1.Q4_0.gguf")
            print("  âœ… Mistralï¼ˆå¤šè¨€èªå¯¾å¿œï¼‰ã‚’ãƒ­ãƒ¼ãƒ‰")
        except Exception as e2:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e2}")
            print("  æ—¢å­˜ã®Orcaãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™")
            model = GPT4All("orca-mini-3b-gguf2-q4_0.gguf")
    
    # æ—¥æœ¬èªãƒ†ã‚¹ãƒˆ
    print("\nã€æ—¥æœ¬èªå¿œç­”ãƒ†ã‚¹ãƒˆã€‘")
    japanese_prompts = [
        "ã“ã‚“ã«ã¡ã¯ã€å…ƒæ°—ã§ã™ã‹ï¼Ÿ",
        "æ—¥æœ¬ã®é¦–éƒ½ã¯ã©ã“ã§ã™ã‹ï¼Ÿ",
        "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "1+1ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "AIã«ã¤ã„ã¦ç°¡å˜ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
    ]
    
    responses = []
    for prompt in japanese_prompts:
        print(f"\n  Q: {prompt}")
        response = model.generate(
            prompt,
            max_tokens=100,
            temp=0.7,
            top_p=0.9
        )
        print(f"  A: {response[:150]}...")
        responses.append((prompt, response))
    
    # 10é€²æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¸è’¸ç•™
    print("\n" + "=" * 50)
    print("ğŸ”¬ 10é€²æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¸æ—¥æœ¬èªè’¸ç•™")
    print("=" * 50)
    
    # ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«
    student = DecimalLLM(hidden_size=64, n_layers=6, context_length=128)
    distiller = LLMDistiller(student)
    
    # æ—¥æœ¬èªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    print("\nã€æ—¥æœ¬èªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä½œæˆã€‘")
    
    japanese_training = [
        # æŒ¨æ‹¶
        "ã“ã‚“ã«ã¡ã¯",
        "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™", 
        "ã“ã‚“ã°ã‚“ã¯",
        "ã•ã‚ˆã†ãªã‚‰",
        "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™",
        "ã™ã¿ã¾ã›ã‚“",
        "ãŠé¡˜ã„ã—ã¾ã™",
        "ã‚ã‹ã‚Šã¾ã—ãŸ",
        # è³ªå•
        "ä»Šä½•æ™‚ã§ã™ã‹ï¼Ÿ",
        "ãŠåå‰ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "ã©ã“ã‹ã‚‰æ¥ã¾ã—ãŸã‹ï¼Ÿ",
        "å¤©æ°—ã¯ã©ã†ã§ã™ã‹ï¼Ÿ",
        # æ•°å­¦
        "1è¶³ã™1ã¯ï¼Ÿ",
        "2ã‹ã‘ã‚‹3ã¯ï¼Ÿ",
        "10å‰²ã‚‹2ã¯ï¼Ÿ",
    ]
    
    for prompt in japanese_training:
        response = model.generate(prompt, max_tokens=50, temp=0.5)
        distiller.add_training_pair(prompt, response)
        print(f"  '{prompt}' â†’ '{response[:35]}...'")
    
    # è’¸ç•™
    print("\nã€è’¸ç•™å®Ÿè¡Œã€‘")
    distiller.distill(epochs=30)
    
    # è©•ä¾¡
    print("\nã€è©•ä¾¡ã€‘")
    results = distiller.evaluate()
    print(f"  ç²¾åº¦: {results['accuracy']:.2%}")
    
    # ã‚µã‚¤ã‚ºæ¯”è¼ƒ
    print("\n" + "=" * 50)
    print("ğŸ“Š ã‚µã‚¤ã‚ºæ¯”è¼ƒ")
    print("=" * 50)
    
    student_stats = student.get_stats()
    print(f"""
| ãƒ¢ãƒ‡ãƒ« | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ã‚µã‚¤ã‚º |
|--------|-----------|--------|
| ELYZA 7B | ~7,000,000,000 | ~4GB |
| 10é€²æ•°LLM | {student_stats['total_neurons']} | ~{student_stats['total_neurons'] * 4 // 1000}KB |

åœ§ç¸®ç‡: {7_000_000_000 // max(1, student_stats['total_neurons']):,}å€!
""")
    
    # æ—¥æœ¬èªç”Ÿæˆãƒ†ã‚¹ãƒˆ
    print("\nã€ç”Ÿæˆãƒ†ã‚¹ãƒˆã€‘")
    test_prompts = ["ã“ã‚“ã«ã¡ã¯", "ã‚ã‚ŠãŒã¨ã†", "å¤©æ°—"]
    for prompt in test_prompts:
        student.clear_context()
        output = student.generate(prompt, max_length=15)
        print(f"  '{prompt}' â†’ '{output}'")
    
    print("\n" + "=" * 70)
    print("âœ… æ—¥æœ¬èªè’¸ç•™å®Œäº†ï¼")
    print("=" * 70)
    
    return student


if __name__ == "__main__":
    main()
