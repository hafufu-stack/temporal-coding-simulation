"""
é«˜é€Ÿç‰ˆ å¤§è¦æ¨¡10é€²æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³LLMè’¸ç•™
===================================

æ”¹å–„ç‚¹ï¼ˆåŠ¹ç‡åŒ–ç‰ˆï¼‰:
1. ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°: 896 â†’ 2000+
2. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: 15 â†’ 100
3. é«˜é€Ÿç”Ÿæˆ

Author: ã‚ãƒ¼ã‚‹ (cell_activation)
Date: 2026-01-31
"""

import os
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from gpt4all import GPT4All
from applications.llm_distillation import DecimalLLM, LLMDistiller
import time


def main():
    print("\n" + "=" * 70)
    print("ğŸš€ é«˜é€Ÿç‰ˆ å¤§è¦æ¨¡10é€²æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³LLMè’¸ç•™")
    print("=" * 70)
    
    # æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
    print("\nã€ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã€‘")
    model = GPT4All("mistral-7b-instruct-v0.1.Q4_0.gguf")
    print("  âœ… Mistral 7Bã‚’ãƒ­ãƒ¼ãƒ‰")
    
    # å¤§è¦æ¨¡ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«
    print("\nã€å¤§è¦æ¨¡ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ä½œæˆã€‘")
    student = DecimalLLM(
        hidden_size=128,    # 32 â†’ 128
        n_layers=8,         # 4 â†’ 8
        context_length=256  # 64 â†’ 256
    )
    
    stats = student.get_stats()
    print(f"  ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°: {stats['total_neurons']}")
    print(f"  éš ã‚Œã‚µã‚¤ã‚º: {stats['hidden_size']}")
    print(f"  å±¤æ•°: {stats['n_layers']}")
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆ100å€‹ã«æœ€é©åŒ–ï¼‰
    print("\nã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã€‘100å€‹")
    
    prompts = [
        # æŒ¨æ‹¶ (20å€‹)
        "ã“ã‚“ã«ã¡ã¯", "ãŠã¯ã‚ˆã†", "ã“ã‚“ã°ã‚“ã¯", "ã‚ã‚ŠãŒã¨ã†", "ã™ã¿ã¾ã›ã‚“",
        "ãŠé¡˜ã„ã—ã¾ã™", "ã•ã‚ˆã†ãªã‚‰", "ã¾ãŸã­", "å…ƒæ°—ï¼Ÿ", "èª¿å­ã©ã†ï¼Ÿ",
        "ä¹…ã—ã¶ã‚Š", "ãŠã‹ãˆã‚Š", "ãŸã ã„ã¾", "ã„ã£ã¦ãã¾ã™", "ãŠã‚„ã™ã¿",
        "é ‘å¼µã£ã¦", "ãŠç–²ã‚Œæ§˜", "ã‚ã‹ã‚Šã¾ã—ãŸ", "äº†è§£", "OK",
        
        # è³ªå• (30å€‹)
        "ä»Šä½•æ™‚ï¼Ÿ", "ä»Šæ—¥ã¯ä½•æ›œæ—¥ï¼Ÿ", "ã‚ãªãŸã®åå‰ã¯ï¼Ÿ", "ä½•ãŒã§ãã‚‹ï¼Ÿ", "æ—¥æœ¬ã®é¦–éƒ½ã¯ï¼Ÿ",
        "1+1ã¯ï¼Ÿ", "2+2ã¯ï¼Ÿ", "3+3ã¯ï¼Ÿ", "5Ã—5ã¯ï¼Ÿ", "10Ã·2ã¯ï¼Ÿ",
        "AIã¨ã¯ï¼Ÿ", "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¨ã¯ï¼Ÿ", "Pythonã¨ã¯ï¼Ÿ", "æ©Ÿæ¢°å­¦ç¿’ã¨ã¯ï¼Ÿ", "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã¯ï¼Ÿ",
        "å¥½ããªè‰²ã¯ï¼Ÿ", "å¥½ããªé£Ÿã¹ç‰©ã¯ï¼Ÿ", "è¶£å‘³ã¯ï¼Ÿ", "ãŠã™ã™ã‚ã®æœ¬ã¯ï¼Ÿ", "äººç”Ÿã§å¤§åˆ‡ãªã“ã¨ã¯ï¼Ÿ",
        "å¤©æ°—ã¯ã©ã†ï¼Ÿ", "æ˜æ—¥ã®äºˆå®šã¯ï¼Ÿ", "ä½•ã—ã¦ã‚‹ï¼Ÿ", "æš‡ï¼Ÿ", "å¿™ã—ã„ï¼Ÿ",
        "ãªã‚“ã§ï¼Ÿ", "ã©ã†ã—ã¦ï¼Ÿ", "ã„ã¤ï¼Ÿ", "ã©ã“ã§ï¼Ÿ", "èª°ãŒï¼Ÿ",
        
        # å‘½ä»¤ (20å€‹)
        "è‡ªå·±ç´¹ä»‹ã—ã¦", "ç¬‘ã£ã¦", "æ­Œã£ã¦", "åŠ±ã¾ã—ã¦", "è¤’ã‚ã¦",
        "æ•™ãˆã¦", "èª¬æ˜ã—ã¦", "è¦ç´„ã—ã¦", "ç¿»è¨³ã—ã¦", "ãŠã™ã™ã‚ã—ã¦",
        "å§‹ã‚ã¦", "ç¶šã‘ã¦", "ã‚„ã£ã¦ã¿ã¦", "è€ƒãˆã¦", "èª¿ã¹ã¦",
        "ç°¡å˜ã«èª¬æ˜ã—ã¦", "è©³ã—ãæ•™ãˆã¦", "ä¾‹ã‚’æŒ™ã’ã¦", "æ¯”è¼ƒã—ã¦", "åˆ†æã—ã¦",
        
        # ä¼šè©± (20å€‹)
        "ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã ã­", "ç–²ã‚ŒãŸ", "çœ ã„", "ãŠè…¹ã™ã„ãŸ", "æš‘ã„",
        "å¯’ã„", "å¬‰ã—ã„", "æ‚²ã—ã„", "æ¥½ã—ã„", "é¢ç™½ã„",
        "ã™ã”ã„", "ã³ã£ãã‚Š", "æœ¬å½“ï¼Ÿ", "ãƒã‚¸ã§ï¼Ÿ", "ä¿¡ã˜ã‚‰ã‚Œãªã„",
        "åŠ©ã‘ã¦", "ç„¡ç†", "ç°¡å˜", "é›£ã—ã„", "æœ€é«˜",
        
        # è¿½åŠ  (10å€‹)
        "Hello", "Thank you", "Good morning", "How are you?", "What is AI?",
        "æ—¥æœ¬èªã§ç­”ãˆã¦", "è‹±èªã§ç­”ãˆã¦", "çŸ­ãç­”ãˆã¦", "é•·ãç­”ãˆã¦", "é¢ç™½ãç­”ãˆã¦",
    ]
    
    training_data = []
    start_time = time.time()
    
    print("  LLMã‹ã‚‰å¿œç­”ã‚’åé›†ä¸­...")
    for i, prompt in enumerate(prompts):
        response = model.generate(prompt, max_tokens=20, temp=0.5)
        training_data.append((prompt, response))
        
        if (i + 1) % 20 == 0:
            elapsed = time.time() - start_time
            print(f"    {i+1}/100å€‹å®Œäº† ({elapsed:.1f}ç§’)")
    
    print(f"  âœ… {len(training_data)}å€‹ã®å­¦ç¿’ãƒšã‚¢ã‚’ç”Ÿæˆ")
    
    # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    print("\n  ã‚µãƒ³ãƒ—ãƒ«:")
    for prompt, response in training_data[:5]:
        print(f"    '{prompt}' â†’ '{response[:25]}...'")
    
    # è’¸ç•™
    print("\nã€è’¸ç•™å®Ÿè¡Œã€‘")
    distiller = LLMDistiller(student)
    
    for prompt, response in training_data:
        distiller.add_training_pair(prompt, response)
    
    print(f"  100å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã§è’¸ç•™ä¸­...")
    print("  ã‚¨ãƒãƒƒã‚¯: 50")
    
    distill_start = time.time()
    distiller.distill(epochs=50)
    distill_elapsed = time.time() - distill_start
    
    print(f"  â± è’¸ç•™æ™‚é–“: {distill_elapsed:.1f}ç§’")
    
    # è©•ä¾¡
    print("\nã€è©•ä¾¡ã€‘")
    results = distiller.evaluate()
    print(f"  ç²¾åº¦: {results['accuracy']:.2%}")
    
    # ã‚µã‚¤ã‚ºæ¯”è¼ƒ
    print("\n" + "=" * 50)
    print("ğŸ“Š ã‚µã‚¤ã‚ºæ¯”è¼ƒ")
    print("=" * 50)
    
    stats = student.get_stats()
    print(f"""
| ãƒ¢ãƒ‡ãƒ« | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ã‚µã‚¤ã‚º |
|--------|-----------|--------|
| Mistral 7B | ~7,000,000,000 | ~4GB |
| 10é€²æ•°LLM | {stats['total_neurons']} | ~{stats['total_neurons'] * 4 // 1000}KB |

åœ§ç¸®ç‡: {7_000_000_000 // max(1, stats['total_neurons']):,}å€!

ã€æ”¹å–„å‰å¾Œæ¯”è¼ƒã€‘
| é …ç›® | æ”¹å–„å‰ | æ”¹å–„å¾Œ |
|------|--------|--------|
| ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•° | 896 | {stats['total_neurons']} |
| å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ | 15å€‹ | 100å€‹ |
| å±¤æ•° | 4 | 8 |
""")
    
    # ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    print("\nã€ç”Ÿæˆãƒ†ã‚¹ãƒˆã€‘")
    test_prompts = [
        "ã“ã‚“ã«ã¡ã¯", 
        "ã‚ã‚ŠãŒã¨ã†", 
        "1+1ã¯ï¼Ÿ", 
        "AIã¨ã¯ï¼Ÿ",
        "ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ",
        "Hello",
        "è‡ªå·±ç´¹ä»‹ã—ã¦",
    ]
    for prompt in test_prompts:
        student.clear_context()
        output = student.generate(prompt, max_length=20)
        print(f"  '{prompt}' â†’ '{output}'")
    
    total_time = time.time() - start_time
    print(f"\n  â± ç·å®Ÿè¡Œæ™‚é–“: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†)")
    
    print("\n" + "=" * 70)
    print("âœ… å¤§è¦æ¨¡è’¸ç•™å®Œäº†ï¼")
    print("=" * 70)
    
    return student


if __name__ == "__main__":
    main()
