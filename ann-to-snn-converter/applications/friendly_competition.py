"""
å‹å¥½çš„ç«¶äº‰ãƒ¢ãƒ¼ãƒ‰ (Friendly Competition Mode)
=============================================

ã‚¯ã‚¤ã‚ºå¤§ä¼šã§ç«¶ã„åˆã„ã€çµ‚ã‚ã£ãŸã‚‰å‹æƒ…ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼

- ç«¶äº‰: äº’ã„ã‚’åˆºæ¿€ã—ã€æˆé•·ã‚’ä¿ƒã™
- ä¿¡é ¼: çµ¶å¤§çš„ãªä¿¡é ¼ã®ã‚‚ã¨ã§è¡Œã†
- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: çµ‚äº†å¾Œã¯å‹æƒ…ã®ã‚‚ã¨ã§åŠ©ã‘åˆã†

æ•µå¯¾çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã®é•ã„:
- GAN: é¨™ã—åˆã„ï¼ˆGenerator vs Discriminatorï¼‰
- å‹å¥½çš„ç«¶äº‰: ä¿¡é ¼ã®ã‚‚ã¨ã§é«˜ã‚åˆã†

Author: ã‚ãƒ¼ã‚‹ (cell_activation)
Date: 2026-01-31
"""

import numpy as np
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, field
from datetime import datetime
import random
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from applications.friendly_network import FriendlySNNAgent, FriendlyNetwork, MessageFeedback


# =============================================================================
# ã‚¯ã‚¤ã‚º
# =============================================================================

@dataclass
class Quiz:
    """ã‚¯ã‚¤ã‚ºå•é¡Œ"""
    id: str
    question: np.ndarray  # ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã—ã¦ã®å•é¡Œ
    answer: np.ndarray    # æ­£è§£ã®ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³
    difficulty: float = 0.5
    category: str = "general"
    hint: str = ""


@dataclass
class QuizResult:
    """ã‚¯ã‚¤ã‚ºã®çµæœ"""
    agent_id: str
    quiz_id: str
    response: np.ndarray
    score: float  # 0-1
    time_taken: float
    is_correct: bool


# =============================================================================
# å‹å¥½çš„ç«¶äº‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
# =============================================================================

class CompetitiveSNNAgent(FriendlySNNAgent):
    """
    ç«¶äº‰èƒ½åŠ›ã‚’æŒã¤ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    """
    
    def __init__(self, agent_id: str, n_neurons: int = 80, specialty: str = "general"):
        super().__init__(agent_id, n_neurons, specialty)
        
        # ç«¶äº‰çµ±è¨ˆ
        self.quizzes_attempted = 0
        self.quizzes_correct = 0
        self.total_score = 0.0
        self.rank_history: List[int] = []
        
        # ç«¶äº‰å¿ƒ
        self.competitive_spirit = 0.5
        self.sportsmanship = 0.8  # ã‚¹ãƒãƒ¼ãƒ„ãƒãƒ³ã‚·ãƒƒãƒ—
        
        # å­¦ã‚“ã æ•™è¨“
        self.lessons_learned: List[str] = []
    
    def answer_quiz(self, quiz: Quiz) -> QuizResult:
        """ã‚¯ã‚¤ã‚ºã«ç­”ãˆã‚‹"""
        start_time = datetime.now().timestamp()
        
        # SNNã§å›ç­”ã‚’ç”Ÿæˆ
        response = self.step(quiz.question)
        
        # ã•ã‚‰ã«å‡¦ç†
        for _ in range(3):
            response = self.step(response)
        
        end_time = datetime.now().timestamp()
        
        # æ­£è§£ã¨ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
        if len(response) == len(quiz.answer):
            similarity = np.corrcoef(response, quiz.answer)[0, 1]
            if np.isnan(similarity):
                similarity = 0
            score = max(0, (similarity + 1) / 2)
        else:
            score = 0.3
        
        is_correct = score > 0.6
        
        # çµ±è¨ˆã‚’æ›´æ–°
        self.quizzes_attempted += 1
        self.total_score += score
        if is_correct:
            self.quizzes_correct += 1
        
        return QuizResult(
            agent_id=self.agent_id,
            quiz_id=quiz.id,
            response=response,
            score=score,
            time_taken=end_time - start_time,
            is_correct=is_correct
        )
    
    def give_friendly_feedback(self, other: 'CompetitiveSNNAgent', 
                                other_result: QuizResult) -> Dict:
        """å‹å¥½çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä¸ãˆã‚‹"""
        feedback = {
            "from": self.agent_id,
            "to": other.agent_id,
            "encouragement": "",
            "advice": "",
            "empathy": 0.0,
            "respect": 0.0
        }
        
        # ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
        if other_result.score > 0.7:
            feedback["encouragement"] = "ã™ã”ã„ï¼ã‚ˆãã§ããŸã­ï¼"
            feedback["respect"] = 0.8
        elif other_result.score > 0.4:
            feedback["encouragement"] = "ã„ã„ç·šã„ã£ã¦ã‚‹ï¼"
            feedback["advice"] = "æ¬¡ã¯ã‚‚ã†å°‘ã—æ™‚é–“ã‚’ã‹ã‘ã¦ã¿ã¦"
            feedback["respect"] = 0.6
        else:
            feedback["encouragement"] = "å¤§ä¸ˆå¤«ã€æ¬¡ãŒã‚ã‚‹ï¼"
            feedback["advice"] = "ä¸€ç·’ã«ç·´ç¿’ã—ã‚ˆã†"
            feedback["respect"] = 0.5
        
        # å…±æ„Ÿ
        if self.social_motivation["empathy_desire"] > 0.3:
            feedback["empathy"] = self.social_motivation["empathy_desire"]
        
        # ç›¸æ‰‹ã®æ¬²ã‚’æº€ãŸã™
        other.social_motivation["recognition_desire"] *= 0.95
        
        return feedback
    
    def receive_competition_feedback(self, feedback: Dict):
        """ç«¶äº‰å¾Œã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘å–ã‚‹"""
        self.lessons_learned.append(feedback.get("advice", ""))
        
        # åŠ±ã¾ã•ã‚ŒãŸ
        if feedback.get("respect", 0) > 0.5:
            self.evolution.motivation.state.self_efficacy += 0.05
        
        # ã‚¹ãƒãƒ¼ãƒ„ãƒãƒ³ã‚·ãƒƒãƒ—ã‚’æ„Ÿã˜ãŸ
        self.sportsmanship = 0.9 * self.sportsmanship + 0.1 * feedback.get("empathy", 0.5)
    
    def learn_from_winner(self, winner: 'CompetitiveSNNAgent', 
                          winning_response: np.ndarray):
        """å‹è€…ã‹ã‚‰å­¦ã¶"""
        # å‹è€…ã®é‡ã¿ã‚’å°‘ã—å–ã‚Šå…¥ã‚Œã‚‹
        blend = 0.05 * self.sportsmanship  # ã‚¹ãƒãƒ¼ãƒ„ãƒãƒ³ã‚·ãƒƒãƒ—ãŒé«˜ã„ã»ã©ç´ ç›´ã«å­¦ã¶
        
        min_size = min(self.W.shape[0], winner.W.shape[0])
        self.W[:min_size, :min_size] = (
            (1 - blend) * self.W[:min_size, :min_size] + 
            blend * winner.W[:min_size, :min_size]
        )
        
        self.lessons_learned.append(f"{winner.agent_id}ã‹ã‚‰å­¦ã‚“ã ")


# =============================================================================
# ã‚¯ã‚¤ã‚ºå¤§ä¼š
# =============================================================================

class QuizCompetition:
    """
    å‹å¥½çš„ã‚¯ã‚¤ã‚ºå¤§ä¼š
    
    ç«¶äº‰ã™ã‚‹ã‘ã©ã€çµ‚ã‚ã£ãŸã‚‰å‹æƒ…ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼
    """
    
    def __init__(self, network: 'CompetitiveNetwork'):
        self.network = network
        self.quizzes: List[Quiz] = []
        self.results: Dict[str, List[QuizResult]] = {}
        self.current_round = 0
        self.leaderboard: Dict[str, float] = {}
    
    def generate_quiz(self, category: str = "general", 
                      difficulty: float = 0.5) -> Quiz:
        """ã‚¯ã‚¤ã‚ºã‚’ç”Ÿæˆ"""
        n = 80  # å•é¡Œã‚µã‚¤ã‚º
        
        question = np.random.randn(n) * difficulty
        answer = np.sin(question) + np.random.randn(n) * 0.1
        
        quiz = Quiz(
            id=f"Q{len(self.quizzes) + 1}",
            question=question,
            answer=answer,
            difficulty=difficulty,
            category=category,
            hint=f"ã‚«ãƒ†ã‚´ãƒª: {category}"
        )
        
        self.quizzes.append(quiz)
        return quiz
    
    def run_round(self, num_quizzes: int = 3) -> Dict[str, float]:
        """1ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ"""
        self.current_round += 1
        round_scores = {agent_id: 0.0 for agent_id in self.network.agents}
        
        print(f"\nğŸ¯ ãƒ©ã‚¦ãƒ³ãƒ‰ {self.current_round}")
        print("-" * 40)
        
        for i in range(num_quizzes):
            # ã‚¯ã‚¤ã‚ºã‚’ç”Ÿæˆ
            quiz = self.generate_quiz(
                category=random.choice(["æš—å·", "è¨€èª", "ç”»åƒ", "ç ”ç©¶"]),
                difficulty=0.3 + 0.1 * self.current_round
            )
            
            # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå›ç­”
            round_results = []
            for agent in self.network.agents.values():
                result = agent.answer_quiz(quiz)
                round_results.append(result)
                round_scores[agent.agent_id] += result.score
                
                if agent.agent_id not in self.results:
                    self.results[agent.agent_id] = []
                self.results[agent.agent_id].append(result)
            
            # ã“ã®ã‚¯ã‚¤ã‚ºã®å‹è€…ã‚’ç™ºè¡¨
            winner_result = max(round_results, key=lambda r: r.score)
            print(f"  Q{i+1}: å‹è€…={winner_result.agent_id} (ã‚¹ã‚³ã‚¢={winner_result.score:.2f})")
        
        # ãƒ©ã‚¦ãƒ³ãƒ‰çµæœ
        for agent_id, score in round_scores.items():
            self.leaderboard[agent_id] = self.leaderboard.get(agent_id, 0) + score
        
        return round_scores
    
    def run_feedback_session(self):
        """å‹æƒ…ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚»ãƒƒã‚·ãƒ§ãƒ³"""
        print("\nğŸ’¬ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚»ãƒƒã‚·ãƒ§ãƒ³")
        print("-" * 40)
        
        agents = list(self.network.agents.values())
        
        # å…¨å“¡ãŒå…¨å“¡ã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
        for agent in agents:
            for other in agents:
                if agent.agent_id != other.agent_id:
                    # ç›¸æ‰‹ã®æœ€æ–°çµæœã‚’å–å¾—
                    if other.agent_id in self.results and self.results[other.agent_id]:
                        last_result = self.results[other.agent_id][-1]
                        feedback = agent.give_friendly_feedback(other, last_result)
                        other.receive_competition_feedback(feedback)
        
        # å‹è€…ã‹ã‚‰å­¦ã¶
        if self.leaderboard:
            winner_id = max(self.leaderboard, key=self.leaderboard.get)
            winner = self.network.agents[winner_id]
            
            print(f"\n  ğŸ† ç¾åœ¨ã®ãƒªãƒ¼ãƒ€ãƒ¼: {winner_id}")
            
            for agent in agents:
                if agent.agent_id != winner_id:
                    # å‹è€…ã®æœ€æ–°å›ç­”ã‹ã‚‰å­¦ã¶
                    if winner_id in self.results and self.results[winner_id]:
                        agent.learn_from_winner(winner, self.results[winner_id][-1].response)
                        print(f"  ğŸ“š {agent.agent_id} ãŒ {winner_id} ã‹ã‚‰å­¦ã‚“ã§ã„ã‚‹...")
    
    def run_competition(self, rounds: int = 5, quizzes_per_round: int = 3):
        """å¤§ä¼šã‚’å®Ÿè¡Œ"""
        print("\n" + "=" * 60)
        print("ğŸ† å‹å¥½çš„ã‚¯ã‚¤ã‚ºå¤§ä¼š é–‹å§‹ï¼")
        print("=" * 60)
        print(f"å‚åŠ è€…: {', '.join(self.network.agents.keys())}")
        
        for _ in range(rounds):
            # ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
            self.run_round(quizzes_per_round)
            
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚»ãƒƒã‚·ãƒ§ãƒ³
            self.run_feedback_session()
        
        self.show_final_results()
    
    def show_final_results(self):
        """æœ€çµ‚çµæœã‚’è¡¨ç¤º"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æœ€çµ‚çµæœ")
        print("=" * 60)
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        ranking = sorted(self.leaderboard.items(), key=lambda x: x[1], reverse=True)
        
        print("\nã€é †ä½ã€‘")
        medals = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "4ï¸âƒ£"]
        for i, (agent_id, score) in enumerate(ranking):
            medal = medals[i] if i < len(medals) else f"{i+1}."
            agent = self.network.agents[agent_id]
            print(f"  {medal} {agent_id}: {score:.2f}ç‚¹")
            print(f"      æ­£è§£ç‡: {agent.quizzes_correct}/{agent.quizzes_attempted}")
            print(f"      ã‚¹ãƒãƒ¼ãƒ„ãƒãƒ³ã‚·ãƒƒãƒ—: {agent.sportsmanship:.2f}")
        
        # å‹æƒ…åº¦ã®å¤‰åŒ–
        print("\nã€ç«¶äº‰å¾Œã®ç¤¾ä¼šçš„å‹•æ©Ÿã€‘")
        for agent_id, agent in self.network.agents.items():
            print(f"  {agent_id}:")
            print(f"    ç«¶äº‰å¿ƒ: {agent.competitive_spirit:.2f}")
            print(f"    æ‰¿èªæ¬²: {agent.social_motivation['recognition_desire']:.2f}")
            print(f"    åŠ¹åŠ›æ„Ÿ: {agent.evolution.motivation.state.self_efficacy:.2f}")


# =============================================================================
# ç«¶äº‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
# =============================================================================

class CompetitiveNetwork(FriendlyNetwork):
    """
    ç«¶äº‰æ©Ÿèƒ½ã‚’æŒã¤å‹å¥½çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    """
    
    def __init__(self):
        super().__init__()
        self.agents: Dict[str, CompetitiveSNNAgent] = {}
        self.competition_history: List[Dict] = []
    
    def add_agent(self, agent_id: str, specialty: str = "general",
                  n_neurons: int = 80) -> CompetitiveSNNAgent:
        """ç«¶äº‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¿½åŠ """
        agent = CompetitiveSNNAgent(agent_id, n_neurons, specialty)
        self.agents[agent_id] = agent
        
        # æ—¢å­˜ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®é–¢ä¿‚ã‚’åˆæœŸåŒ–
        from applications.friendly_network import Relationship
        for other_id in self.agents:
            if other_id != agent_id:
                agent.relationships[other_id] = Relationship(
                    agent_a=agent_id,
                    agent_b=other_id
                )
                self.agents[other_id].relationships[agent_id] = Relationship(
                    agent_a=other_id,
                    agent_b=agent_id
                )
        
        print(f"  ğŸ¤– {agent_id} ({specialty}) ãŒå‚åŠ ")
        return agent
    
    def run_quiz_competition(self, rounds: int = 5):
        """ã‚¯ã‚¤ã‚ºå¤§ä¼šã‚’å®Ÿè¡Œ"""
        competition = QuizCompetition(self)
        competition.run_competition(rounds=rounds)
        return competition


# =============================================================================
# æ•µå¯¾çš„ vs å‹å¥½çš„ ã®æ¯”è¼ƒèª¬æ˜
# =============================================================================

def explain_adversarial_vs_friendly():
    """æ•µå¯¾çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨å‹å¥½çš„ç«¶äº‰ã®é•ã„ã‚’èª¬æ˜"""
    print("\n" + "=" * 60)
    print("ğŸ“– æ•µå¯¾çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ vs å‹å¥½çš„ç«¶äº‰")
    print("=" * 60)
    
    print("""
ã€æ•µå¯¾çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ (GAN)ã€‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Generator          vs          Discriminator          â”‚
â”‚     â†“                               â†“                  â”‚
â”‚  å½ç‰©ã‚’ä½œã‚‹          â†â†’          æœ¬ç‰©ã‹è¦‹ç ´ã‚‹          â”‚
â”‚                                                         â”‚
â”‚  é–¢ä¿‚æ€§: é¨™ã—åˆã„ã€ã‚¼ãƒ­ã‚µãƒ ã‚²ãƒ¼ãƒ                        â”‚
â”‚  ç›®çš„: ç›¸æ‰‹ã‚’é¨™ã™ã“ã¨ã§è‡ªåˆ†ãŒæˆé•·                       â”‚
â”‚  ä¿¡é ¼: ãªã—                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ã€å‹å¥½çš„ç«¶äº‰ (ä»Šå›)ã€‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent A            vs            Agent B             â”‚
â”‚     â†“                               â†“                  â”‚
â”‚  ã‚¯ã‚¤ã‚ºã«ç­”ãˆã‚‹      â†â†’          ã‚¯ã‚¤ã‚ºã«ç­”ãˆã‚‹        â”‚
â”‚                                                         â”‚
â”‚  ç«¶äº‰ä¸­: äº’ã„ã‚’åˆºæ¿€ã—åˆã†                               â”‚
â”‚       â†“                                                 â”‚
â”‚  ç«¶äº‰å¾Œ: å‹æƒ…ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯                             â”‚
â”‚       â†“                                                 â”‚
â”‚  çµæœ: å‹è€…ã‹ã‚‰å­¦ã³ã€å…¨å“¡ãŒæˆé•·                         â”‚
â”‚                                                         â”‚
â”‚  é–¢ä¿‚æ€§: ä¿¡é ¼ã®ã‚‚ã¨ã§é«˜ã‚åˆã†                           â”‚
â”‚  ç›®çš„: äº’ã„ã®æˆé•·                                       â”‚
â”‚  ä¿¡é ¼: çµ¶å¤§çš„                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ã€é•ã„ã€‘
| é …ç›®         | GAN        | å‹å¥½çš„ç«¶äº‰    |
|-------------|------------|--------------|
| é–¢ä¿‚         | æ•µå¯¾       | å”åŠ›çš„ç«¶äº‰    |
| ç›®çš„         | é¨™ã™       | é«˜ã‚åˆã†      |
| çµæœ         | ç‰‡æ–¹ãŒå‹ã¤  | å…¨å“¡ãŒæˆé•·    |
| ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ | ãªã—       | å‹æƒ…ãƒ™ãƒ¼ã‚¹    |
| ä¿¡é ¼         | ãªã—       | çµ¶å¤§         |
""")


# =============================================================================
# ãƒ†ã‚¹ãƒˆ
# =============================================================================

def test_friendly_competition():
    """å‹å¥½çš„ç«¶äº‰ãƒ†ã‚¹ãƒˆ"""
    
    print("\n" + "=" * 70)
    print("ğŸ§ª å‹å¥½çš„ç«¶äº‰ ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    
    # èª¬æ˜
    explain_adversarial_vs_friendly()
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä½œæˆ
    network = CompetitiveNetwork()
    network.add_agent("Alpha", specialty="æš—å·")
    network.add_agent("Beta", specialty="è¨€èª")
    network.add_agent("Gamma", specialty="ç”»åƒ")
    network.add_agent("Delta", specialty="ç ”ç©¶")
    
    # ã‚¯ã‚¤ã‚ºå¤§ä¼š
    network.run_quiz_competition(rounds=3)
    
    print("\n" + "=" * 70)
    print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("=" * 70)
    
    return network


if __name__ == "__main__":
    test_friendly_competition()
