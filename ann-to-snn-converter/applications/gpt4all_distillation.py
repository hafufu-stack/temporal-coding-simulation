"""
GPT4All + 10é€²æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ è’¸ç•™çµ±åˆ
===================================

GPT4Allã‹ã‚‰10é€²æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³LLMã¸ã®è’¸ç•™

ç‰¹å¾´:
- GPT4Allã®å¿œç­”ã‚’æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åé›†
- 10é€²æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«çŸ¥è­˜ã‚’è’¸ç•™
- ãƒ­ãƒ¼ã‚«ãƒ«å®Œçµï¼ˆãƒãƒƒãƒˆä¸è¦ï¼‰

Author: ã‚ãƒ¼ã‚‹ (cell_activation)
Date: 2026-01-31
"""

import numpy as np
from typing import List, Dict, Tuple, Optional
import os
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# GPT4AllãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
try:
    from gpt4all import GPT4All
    GPT4ALL_AVAILABLE = True
except ImportError:
    GPT4ALL_AVAILABLE = False
    print("è­¦å‘Š: GPT4AllãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("  pip install gpt4all ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")

from applications.llm_distillation import DecimalLLM, LLMDistiller


# =============================================================================
# GPT4Allæ•™å¸«ãƒ¢ãƒ‡ãƒ«
# =============================================================================

class GPT4AllTeacher:
    """
    GPT4Allã‚’æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ä½¿ç”¨
    """
    
    # åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªå¯¾å¿œãƒ¢ãƒ‡ãƒ«
    JAPANESE_MODELS = [
        "Phi-3-mini-4k-instruct.Q4_0.gguf",  # å¤šè¨€èªå¯¾å¿œ
        "mistral-7b-instruct-v0.1.Q4_0.gguf",  # å¤šè¨€èª
        "orca-mini-3b-gguf2-q4_0.gguf",  # è»½é‡
    ]
    
    def __init__(self, model_name: str = None):
        if not GPT4ALL_AVAILABLE:
            raise RuntimeError("GPT4AllãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.model_name = model_name
        self.model = None
        self.responses_cache: Dict[str, str] = {}
    
    def load_model(self, model_name: str = None):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
        if model_name:
            self.model_name = model_name
        
        if not self.model_name:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è»½é‡ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            self.model_name = "orca-mini-3b-gguf2-q4_0.gguf"
        
        print(f"  ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {self.model_name}")
        print("  (åˆå›ã¯è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™)")
        
        try:
            self.model = GPT4All(self.model_name)
            print(f"  âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            return True
        except Exception as e:
            print(f"  âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
            return False
    
    def generate(self, prompt: str, max_tokens: int = 100, 
                 temperature: float = 0.7) -> str:
        """å¿œç­”ã‚’ç”Ÿæˆ"""
        if not self.model:
            return ""
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
        cache_key = f"{prompt}_{max_tokens}_{temperature}"
        if cache_key in self.responses_cache:
            return self.responses_cache[cache_key]
        
        try:
            response = self.model.generate(
                prompt,
                max_tokens=max_tokens,
                temp=temperature,
                top_p=0.9,
                repeat_penalty=1.1
            )
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self.responses_cache[cache_key] = response
            return response
            
        except Exception as e:
            print(f"  ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def generate_training_pairs(self, prompts: List[str]) -> List[Tuple[str, str]]:
        """å­¦ç¿’ç”¨ãƒšã‚¢ã‚’ç”Ÿæˆ"""
        pairs = []
        
        for prompt in prompts:
            response = self.generate(prompt, max_tokens=50)
            if response:
                pairs.append((prompt, response))
        
        return pairs


# =============================================================================
# è’¸ç•™ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
# =============================================================================

class GPT4AllDistillationPipeline:
    """
    GPT4All â†’ 10é€²æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ è’¸ç•™ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    """
    
    def __init__(self, student_hidden_size: int = 32, student_layers: int = 4):
        # æ•™å¸«ãƒ¢ãƒ‡ãƒ«
        self.teacher = None
        
        # ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ï¼ˆ10é€²æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼‰
        self.student = DecimalLLM(
            hidden_size=student_hidden_size,
            n_layers=student_layers,
            context_length=64
        )
        
        # è’¸ç•™å™¨
        self.distiller = LLMDistiller(self.student)
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
        self.training_data: List[Tuple[str, str]] = []
    
    def load_teacher(self, model_name: str = None) -> bool:
        """æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
        if not GPT4ALL_AVAILABLE:
            print("  GPT4AllãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™ã€‚")
            return False
        
        self.teacher = GPT4AllTeacher(model_name)
        return self.teacher.load_model()
    
    def collect_training_data(self, prompts: List[str] = None):
        """æ•™å¸«ã‹ã‚‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’åé›†"""
        if prompts is None:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            prompts = [
                "ã“ã‚“ã«ã¡ã¯",
                "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™",
                "ã‚ã‚ŠãŒã¨ã†",
                "ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ",
                "1+1ã¯ä½•ï¼Ÿ",
                "AIã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
                "æ—¥æœ¬ã®é¦–éƒ½ã¯ï¼Ÿ",
                "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¨ã¯ï¼Ÿ",
            ]
        
        print(f"\n  {len(prompts)}å€‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...")
        
        if self.teacher and GPT4ALL_AVAILABLE:
            # GPT4Allã‹ã‚‰å¿œç­”ã‚’åé›†
            self.training_data = self.teacher.generate_training_pairs(prompts)
        else:
            # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿
            self.training_data = self._create_simulation_data(prompts)
        
        print(f"  âœ… {len(self.training_data)}å€‹ã®å­¦ç¿’ãƒšã‚¢ã‚’åé›†")
        
        for inp, out in self.training_data[:3]:
            print(f"    '{inp}' â†’ '{out[:30]}...'")
    
    def _create_simulation_data(self, prompts: List[str]) -> List[Tuple[str, str]]:
        """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆGPT4Allãªã—ã§ã‚‚ãƒ†ã‚¹ãƒˆå¯èƒ½ï¼‰"""
        simulation_responses = {
            "ã“ã‚“ã«ã¡ã¯": "ã“ã‚“ã«ã¡ã¯ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™": "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ï¼è‰¯ã„ä¸€æ—¥ã‚’ï¼",
            "ã‚ã‚ŠãŒã¨ã†": "ã©ã†ã„ãŸã—ã¾ã—ã¦ï¼",
            "ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ": "ä»Šæ—¥ã¯æ™´ã‚Œã®äºˆå ±ã§ã™ã€‚",
            "1+1ã¯ä½•ï¼Ÿ": "1+1ã¯2ã§ã™ã€‚",
            "AIã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ": "AIã¯äººå·¥çŸ¥èƒ½ã®ç•¥ã§ã€æ©Ÿæ¢°ãŒçŸ¥çš„ãªã‚¿ã‚¹ã‚¯ã‚’è¡Œã†æŠ€è¡“ã§ã™ã€‚",
            "æ—¥æœ¬ã®é¦–éƒ½ã¯ï¼Ÿ": "æ—¥æœ¬ã®é¦–éƒ½ã¯æ±äº¬ã§ã™ã€‚",
            "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¨ã¯ï¼Ÿ": "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¯ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã«å‘½ä»¤ã‚’ä¸ãˆã‚‹æ–¹æ³•ã§ã™ã€‚",
        }
        
        pairs = []
        for prompt in prompts:
            response = simulation_responses.get(prompt, f"{prompt}ã¸ã®å¿œç­”")
            pairs.append((prompt, response))
        
        return pairs
    
    def distill(self, epochs: int = 20):
        """è’¸ç•™ã‚’å®Ÿè¡Œ"""
        print("\n" + "=" * 50)
        print("ğŸ”¬ è’¸ç•™é–‹å§‹")
        print("=" * 50)
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        for inp, out in self.training_data:
            self.distiller.add_training_pair(inp, out)
        
        # è’¸ç•™å®Ÿè¡Œ
        final_acc = self.distiller.distill(epochs=epochs)
        
        return final_acc
    
    def evaluate(self):
        """è©•ä¾¡"""
        print("\nã€è©•ä¾¡ã€‘")
        results = self.distiller.evaluate()
        print(f"  ç²¾åº¦: {results['accuracy']:.2%}")
        
        for ex in results["examples"][:3]:
            status = "âœ“" if ex["correct"] else "âœ—"
            print(f"  {status} '{ex['input']}' â†’ '{ex['output'][:25]}...'")
        
        return results
    
    def compare_sizes(self):
        """ã‚µã‚¤ã‚ºæ¯”è¼ƒ"""
        print("\n" + "=" * 50)
        print("ğŸ“Š ã‚µã‚¤ã‚ºæ¯”è¼ƒ")
        print("=" * 50)
        
        teacher_params = 3_000_000_000  # 3Bï¼ˆæ¨å®šï¼‰
        student_stats = self.student.get_stats()
        student_params = student_stats["total_neurons"]
        
        compression = teacher_params / max(1, student_params)
        
        print(f"""
| ãƒ¢ãƒ‡ãƒ« | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | æ¨å®šã‚µã‚¤ã‚º |
|--------|-----------|-----------|
| GPT4All (3B) | {teacher_params:,} | ~6GB |
| 10é€²æ•°LLM | {student_params:,} | ~{student_params * 4 // 1000}KB |

åœ§ç¸®ç‡: {compression:,.0f}å€ å°ã•ã„ï¼
""")


# =============================================================================
# ãƒ†ã‚¹ãƒˆ
# =============================================================================

def test_gpt4all_distillation():
    """GPT4Allè’¸ç•™ãƒ†ã‚¹ãƒˆ"""
    
    print("\n" + "=" * 70)
    print("ğŸ§ª GPT4All â†’ 10é€²æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ è’¸ç•™ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæˆ
    pipeline = GPT4AllDistillationPipeline(
        student_hidden_size=32,
        student_layers=4
    )
    
    # æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
    print("\nã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã€‘")
    if GPT4ALL_AVAILABLE:
        # è»½é‡ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼ˆåˆå›ã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«æ™‚é–“ãŒã‹ã‹ã‚‹ï¼‰
        # pipeline.load_teacher("orca-mini-3b-gguf2-q4_0.gguf")
        print("  GPT4Allåˆ©ç”¨å¯èƒ½ï¼")
        print("  â€»ä»Šå›ã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§ãƒ†ã‚¹ãƒˆ")
    else:
        print("  GPT4Allæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰")
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åé›†
    print("\nã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åé›†ã€‘")
    pipeline.collect_training_data()
    
    # è’¸ç•™
    pipeline.distill(epochs=15)
    
    # è©•ä¾¡
    pipeline.evaluate()
    
    # ã‚µã‚¤ã‚ºæ¯”è¼ƒ
    pipeline.compare_sizes()
    
    print("\n" + "=" * 70)
    print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("=" * 70)
    
    return pipeline


def demo_with_gpt4all():
    """GPT4Allã‚’å®Ÿéš›ã«ä½¿ã†ãƒ‡ãƒ¢"""
    
    if not GPT4ALL_AVAILABLE:
        print("GPT4AllãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    print("\n" + "=" * 70)
    print("ğŸ¤– GPT4All å®Ÿå‹•ãƒ‡ãƒ¢")
    print("=" * 70)
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    pipeline = GPT4AllDistillationPipeline()
    
    # æ•™å¸«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ï¼‰
    print("\nã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã€‘")
    print("  â€»åˆå›ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«æ•°åˆ†ã‹ã‹ã‚Šã¾ã™")
    
    if pipeline.load_teacher("orca-mini-3b-gguf2-q4_0.gguf"):
        # ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        prompts = ["Hello", "What is AI?", "1+1=?"]
        
        print("\nã€GPT4Allå¿œç­”ãƒ†ã‚¹ãƒˆã€‘")
        for prompt in prompts:
            response = pipeline.teacher.generate(prompt, max_tokens=30)
            print(f"  Q: {prompt}")
            print(f"  A: {response[:50]}...")
            print()
        
        # è’¸ç•™
        pipeline.collect_training_data(prompts)
        pipeline.distill(epochs=10)
        pipeline.evaluate()


if __name__ == "__main__":
    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ
    test_gpt4all_distillation()
    
    # GPT4Allã‚’å®Ÿéš›ã«ä½¿ã†å ´åˆã¯ã“ã¡ã‚‰
    # demo_with_gpt4all()
