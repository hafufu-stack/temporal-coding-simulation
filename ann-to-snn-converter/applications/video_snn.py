"""
è‡ªå¾‹é€²åŒ– å‹•ç”»SNN (Evolving Video SNN)
=====================================

è£œé–“å“è³ªã‚’è‡ªå‹•æ”¹å–„ã—ã€éŸ³å£°ç”Ÿæˆã‚’æ´—ç·´ã™ã‚‹è‡ªå¾‹é€²åŒ–å‹•ç”»å‡¦ç†SNN

Author: ã‚ãƒ¼ã‚‹ (cell_activation)
"""

import numpy as np
from typing import Dict, List, Tuple
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.evolution_engine import EvolvingSNN


class EvolvingVideoSNN(EvolvingSNN):
    """
    è‡ªå¾‹é€²åŒ–ã™ã‚‹å‹•ç”»å‡¦ç†SNN
    
    è‡ªå‹•ã§:
    - ãƒ•ãƒ¬ãƒ¼ãƒ è£œé–“å“è³ªã‚’æ”¹å–„
    - è¶…è§£åƒã‚’å‘ä¸Š
    - éŸ³å£°ç”Ÿæˆã‚’æ´—ç·´
    """
    
    def __init__(self, n_neurons: int = 200):
        super().__init__(n_neurons)
        
        # å‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.params = {
            "interpolation_smoothness": 0.5,
            "upscale_sharpness": 0.5,
            "audio_richness": 0.5
        }
        
        # ã‚¹ã‚­ãƒ«
        self.skills = {
            "interpolation": 0.5,
            "upscaling": 0.5,
            "audio_sync": 0.5
        }
    
    def interpolate_frames(self, frame1: np.ndarray, frame2: np.ndarray,
                           n_frames: int = 5) -> List[np.ndarray]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ è£œé–“"""
        interpolated = []
        
        # SNNã§è£œé–“ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’ç”Ÿæˆ
        timings = []
        for i in range(n_frames):
            t = (i + 1) / (n_frames + 1)
            input_vec = np.array([t, 1-t] + [0] * (self.n_neurons - 2))
            output = self.step(input_vec)
            
            # éç·šå½¢ã‚¿ã‚¤ãƒŸãƒ³ã‚°
            snn_t = np.clip(t + np.mean(output) * 0.1, 0, 1)
            timings.append(snn_t)
        
        smoothness = self.params["interpolation_smoothness"]
        
        for t in timings:
            # ãƒ–ãƒ¬ãƒ³ãƒ‰
            blended = (1 - t) * frame1 + t * frame2
            
            # ã‚¹ãƒ ãƒ¼ã‚ºãƒã‚¹ã‚’é©ç”¨
            if smoothness > 0.5:
                # ã‚¨ãƒƒã‚¸ã‚’ã‚½ãƒ•ãƒˆåŒ–
                kernel_size = int(smoothness * 3)
                if kernel_size > 0:
                    # ç°¡æ˜“ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼
                    blended = self._simple_blur(blended, kernel_size)
            
            interpolated.append(blended.astype(np.uint8))
        
        return interpolated
    
    def _simple_blur(self, image: np.ndarray, size: int) -> np.ndarray:
        """ç°¡æ˜“ãƒ–ãƒ©ãƒ¼"""
        from scipy.ndimage import uniform_filter
        try:
            return uniform_filter(image.astype(float), size=size)
        except:
            return image
    
    def upscale(self, image: np.ndarray, scale: int = 2) -> np.ndarray:
        """è¶…è§£åƒ"""
        h, w = image.shape[:2]
        new_h, new_w = h * scale, w * scale
        
        # åŸºæœ¬çš„ãªã‚¢ãƒƒãƒ—ã‚¹ã‚±ãƒ¼ãƒ«
        if len(image.shape) == 3:
            upscaled = np.zeros((new_h, new_w, image.shape[2]))
            for c in range(image.shape[2]):
                upscaled[:, :, c] = self._bilinear_upscale(image[:, :, c], scale)
        else:
            upscaled = self._bilinear_upscale(image, scale)
        
        # SNNã§ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«è¿½åŠ 
        sharpness = self.params["upscale_sharpness"]
        if sharpness > 0.3:
            # ã‚·ãƒ£ãƒ¼ãƒ—åŒ–
            upscaled = self._sharpen(upscaled, sharpness)
        
        return np.clip(upscaled, 0, 255).astype(np.uint8)
    
    def _bilinear_upscale(self, channel: np.ndarray, scale: int) -> np.ndarray:
        """ãƒã‚¤ãƒªãƒ‹ã‚¢è£œé–“"""
        h, w = channel.shape
        new_h, new_w = h * scale, w * scale
        
        result = np.zeros((new_h, new_w))
        for i in range(new_h):
            for j in range(new_w):
                src_i = i / scale
                src_j = j / scale
                
                i0, j0 = int(src_i), int(src_j)
                i1, j1 = min(i0 + 1, h - 1), min(j0 + 1, w - 1)
                
                di, dj = src_i - i0, src_j - j0
                
                result[i, j] = (
                    channel[i0, j0] * (1 - di) * (1 - dj) +
                    channel[i1, j0] * di * (1 - dj) +
                    channel[i0, j1] * (1 - di) * dj +
                    channel[i1, j1] * di * dj
                )
        
        return result
    
    def _sharpen(self, image: np.ndarray, strength: float) -> np.ndarray:
        """ã‚·ãƒ£ãƒ¼ãƒ—åŒ–"""
        # ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ã®è¿‘ä¼¼
        if len(image.shape) == 3:
            for c in range(image.shape[2]):
                channel = image[:, :, c]
                h, w = channel.shape
                
                laplacian = np.zeros_like(channel)
                laplacian[1:-1, 1:-1] = (
                    4 * channel[1:-1, 1:-1] -
                    channel[:-2, 1:-1] - channel[2:, 1:-1] -
                    channel[1:-1, :-2] - channel[1:-1, 2:]
                )
                
                image[:, :, c] = channel + strength * laplacian * 0.1
        
        return image
    
    def generate_audio(self, duration: float, 
                       scene_hints: List[str] = None) -> np.ndarray:
        """éŸ³å£°ç”Ÿæˆ"""
        sample_rate = 44100
        n_samples = int(duration * sample_rate)
        
        audio = np.zeros(n_samples)
        richness = self.params["audio_richness"]
        
        # SNNã§éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        freq_base = 200 + 300 * richness
        
        t = np.linspace(0, duration, n_samples)
        
        # åŸºæœ¬æ³¢å½¢
        audio = np.sin(2 * np.pi * freq_base * t) * 0.3
        
        # å€éŸ³ã‚’è¿½åŠ 
        for harmonic in range(2, int(richness * 5) + 2):
            audio += np.sin(2 * np.pi * freq_base * harmonic * t) * 0.1 / harmonic
        
        # ãƒã‚¤ã‚º
        audio += np.random.randn(n_samples) * 0.05 * richness
        
        return np.clip(audio, -1, 1)
    
    def evolve_quality(self, sample_frames: List[np.ndarray] = None):
        """å“è³ªã‚’é€²åŒ–ã•ã›ã‚‹"""
        # è©•ä¾¡
        quality = np.mean(list(self.params.values()))
        
        # çµŒé¨“ã¨ã—ã¦è¨˜éŒ²
        self.experience(
            np.random.randn(self.n_neurons),
            skill="interpolation",
            target=np.ones(self.n_neurons) * quality
        )
        
        # é€²åŒ–
        result = self.evolve(verbose=True)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
        if result.get("action") in ["optimize", "explore"]:
            for key in self.params:
                self.params[key] = np.clip(
                    self.params[key] + np.random.randn() * 0.05,
                    0.1, 0.9
                )
        
        return {"quality": quality, "params": self.params, "evolution": result}


def test_video_snn():
    """ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 70)
    print("ğŸ¬ è‡ªå¾‹é€²åŒ– å‹•ç”»SNN ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    
    snn = EvolvingVideoSNN(n_neurons=100)
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ è£œé–“ãƒ†ã‚¹ãƒˆ
    print("\n--- ãƒ•ãƒ¬ãƒ¼ãƒ è£œé–“ ---")
    frame1 = np.random.randint(0, 256, (32, 32, 3), dtype=np.uint8)
    frame2 = np.random.randint(0, 256, (32, 32, 3), dtype=np.uint8)
    
    interpolated = snn.interpolate_frames(frame1, frame2, n_frames=3)
    print(f"  å…¥åŠ›: 2ãƒ•ãƒ¬ãƒ¼ãƒ  â†’ å‡ºåŠ›: {len(interpolated)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
    
    # è¶…è§£åƒãƒ†ã‚¹ãƒˆ
    print("\n--- è¶…è§£åƒ ---")
    small = np.random.randint(0, 256, (16, 16, 3), dtype=np.uint8)
    large = snn.upscale(small, scale=2)
    print(f"  {small.shape} â†’ {large.shape}")
    
    # éŸ³å£°ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    print("\n--- éŸ³å£°ç”Ÿæˆ ---")
    audio = snn.generate_audio(1.0)
    print(f"  1ç§’ â†’ {len(audio)}ã‚µãƒ³ãƒ—ãƒ«")
    
    # å“è³ªé€²åŒ–
    print("\n--- å“è³ªé€²åŒ– ---")
    for i in range(3):
        result = snn.evolve_quality()
        print(f"ã‚µã‚¤ã‚¯ãƒ«{i+1}: å“è³ª={result['quality']:.2f}")
    
    snn.report()
    
    print("\n" + "=" * 70)
    print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("=" * 70)


if __name__ == "__main__":
    test_video_snn()
