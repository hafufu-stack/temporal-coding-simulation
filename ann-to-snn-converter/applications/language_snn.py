"""
è‡ªå¾‹é€²åŒ– è¨€èªSNN (Evolving Language SNN)
========================================

èªå½™ã‚’è‡ªå‹•æ‹¡å¼µã—ã€æ–‡æ³•ã‚’è‡ªå·±ä¿®æ­£ã™ã‚‹è‡ªå¾‹é€²åŒ–SNN-LLM

Author: ã‚ãƒ¼ã‚‹ (cell_activation)
"""

import numpy as np
from typing import Dict, List, Tuple, Optional
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.evolution_engine import EvolvingSNN


class EvolvingLanguageSNN(EvolvingSNN):
    """
    è‡ªå¾‹é€²åŒ–ã™ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«SNN
    
    è‡ªå‹•ã§:
    - èªå½™ã‚’æ‹¡å¼µ
    - æ–‡æ³•ã‚¨ãƒ©ãƒ¼ã‚’è‡ªå·±ä¿®æ­£
    - è¡¨ç¾åŠ›ã‚’å‘ä¸Š
    """
    
    def __init__(self, n_neurons: int = 200):
        super().__init__(n_neurons)
        
        # èªå½™
        self.vocabulary: Dict[str, int] = {}
        self.id_to_word: Dict[int, str] = {}
        self.vocab_size = 0
        
        # æ–‡æ³•ãƒ«ãƒ¼ãƒ«ï¼ˆç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        self.forbidden_patterns = ["ã‚’ã¨", "ã¦ã‚‚ã‚’", "ãŒãŒ", "ã¯ã¯"]
        
        # å­¦ç¿’ã—ãŸæ–‡
        self.learned_sentences: List[str] = []
        
        # ã‚¹ã‚­ãƒ«
        self.skills = {
            "vocabulary": 0.5,
            "grammar": 0.5,
            "fluency": 0.5
        }
    
    def add_word(self, word: str):
        """èªå½™ã«å˜èªã‚’è¿½åŠ """
        if word not in self.vocabulary:
            self.vocabulary[word] = self.vocab_size
            self.id_to_word[self.vocab_size] = word
            self.vocab_size += 1
            
            # è‡ªå·±æˆé•·ã‚’è¨˜éŒ²
            self.evolution.motivation.state.satisfaction += 0.01
    
    def learn_sentence(self, sentence: str):
        """æ–‡ã‹ã‚‰å­¦ç¿’"""
        # å˜èªã‚’è¿½åŠ 
        words = list(sentence)  # æ–‡å­—å˜ä½
        for word in words:
            self.add_word(word)
        
        self.learned_sentences.append(sentence)
        
        # æ–‡æ³•ãƒã‚§ãƒƒã‚¯
        grammar_score = self._check_grammar(sentence)
        
        # çµŒé¨“ã¨ã—ã¦è¨˜éŒ²
        input_vec = np.zeros(self.n_neurons)
        for i, char in enumerate(sentence[:self.n_neurons]):
            if char in self.vocabulary:
                input_vec[i] = self.vocabulary[char] / self.vocab_size
        
        self.experience(input_vec, skill="grammar", target=np.ones(self.n_neurons) * grammar_score)
    
    def generate(self, prompt: str = "", length: int = 20) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ"""
        result = prompt
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        if prompt:
            input_vec = np.zeros(self.n_neurons)
            for i, char in enumerate(prompt[:self.n_neurons]):
                if char in self.vocabulary:
                    input_vec[i] = self.vocabulary[char] / max(1, self.vocab_size)
        else:
            input_vec = np.random.randn(self.n_neurons) * 0.3
        
        # ç”Ÿæˆ
        for _ in range(length):
            output = self.step(input_vec)
            
            # æœ€ã‚‚æ´»æ€§åŒ–ã—ãŸãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‹ã‚‰æ–‡å­—ã‚’é¸æŠ
            if self.vocab_size > 0:
                idx = int(np.argmax(output[:self.vocab_size]) % self.vocab_size)
                char = self.id_to_word.get(idx, "")
                result += char
                
                # å…¥åŠ›ã‚’æ›´æ–°
                input_vec = np.roll(input_vec, -1)
                input_vec[-1] = idx / self.vocab_size
        
        # æ–‡æ³•ãƒ•ã‚£ãƒ«ã‚¿
        result = self._filter_grammar(result)
        
        return result
    
    def _check_grammar(self, text: str) -> float:
        """æ–‡æ³•ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        score = 1.0
        
        for pattern in self.forbidden_patterns:
            if pattern in text:
                score -= 0.1
        
        return max(0, score)
    
    def _filter_grammar(self, text: str) -> str:
        """ç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ•ã‚£ãƒ«ã‚¿"""
        for pattern in self.forbidden_patterns:
            text = text.replace(pattern, pattern[0])
        return text
    
    def evolve_vocabulary(self):
        """èªå½™ã‚’é€²åŒ–çš„ã«æ‹¡å¼µ"""
        # å¥½å¥‡å¿ƒãŒé«˜ã„å ´åˆã€æ–°ã—ã„æ–‡å­—ã‚’æ¢ç´¢
        if self.evolution.motivation.state.curiosity > 0.5:
            # ãƒ©ãƒ³ãƒ€ãƒ ãªæ–‡å­—ã‚’è¿½åŠ ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
            new_chars = "ã‚ã„ã†ãˆãŠ"
            for char in new_chars:
                self.add_word(char)
    
    def auto_learn_cycle(self, texts: List[str]):
        """è‡ªå‹•å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«"""
        print(f"\nğŸ“š {len(texts)}å€‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å­¦ç¿’ä¸­...")
        
        for text in texts:
            self.learn_sentence(text)
        
        print(f"  èªå½™ã‚µã‚¤ã‚º: {self.vocab_size}")
        
        # é€²åŒ–
        self.evolve(verbose=True)


def test_language_snn():
    """ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 70)
    print("ğŸ“ è‡ªå¾‹é€²åŒ– è¨€èªSNN ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    
    snn = EvolvingLanguageSNN(n_neurons=100)
    
    # å­¦ç¿’
    training_texts = [
        "ä»Šæ—¥ã¯å¤©æ°—ãŒã„ã„",
        "æ˜æ—¥ã‚‚æ™´ã‚Œã‚‹ã¨ã„ã„ãª",
        "SNNã§è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹",
        "è‡ªå¾‹é€²åŒ–ã™ã‚‹äººå·¥çŸ¥èƒ½",
    ]
    
    snn.auto_learn_cycle(training_texts)
    
    # ç”Ÿæˆ
    print("\n--- ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ ---")
    for prompt in ["ä»Šæ—¥", "SNN", ""]:
        generated = snn.generate(prompt, length=15)
        print(f"  ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€Œ{prompt}ã€â†’ã€Œ{generated}ã€")
    
    # è‡ªå¾‹é‹è»¢
    print("\n--- è‡ªå¾‹é€²åŒ– ---")
    snn.run_autonomous(cycles=3, experience_per_cycle=10)
    
    print("\n" + "=" * 70)
    print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("=" * 70)


if __name__ == "__main__":
    test_language_snn()
